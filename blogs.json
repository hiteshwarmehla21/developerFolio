{"status":"ok","feed":{"url":"https://medium.com/feed/@@paruldhingra","title":"Stories by Parul Dhingra on Medium","link":"https://medium.com/@paruldhingra?source=rss-6e9b39ccfd81------2","author":"","description":"Stories by Parul Dhingra on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/1*Um13BKqkwbnAPA7GzVSUGQ.jpeg"},"items":[{"title":"Unlocking some proven methods to boost your SQL Query Speed:","pubDate":"2023-04-29 11:10:37","link":"https://medium.com/@paruldhingra/unlocking-some-proven-methods-to-boost-your-sql-query-speed-d9d18260aa6b?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/d9d18260aa6b","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/841/1*3GQy18iMCxegCVul6AQrXg.png","description":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/841/1*3GQy18iMCxegCVul6AQrXg.png\"></figure><p>Before you optimize your queries, you have to decide which ones are best to optimize. If you are less selective when deciding which queries to optimize, you may end up wasting time and money by optimizing those that don\u2019t significantly contribute to performance, don\u2019t impact other queries, or don\u2019t result in problems users will\u00a0notice.</p>\n<p><em>Unfortunately, many people skip this critical step\u00a0!\u00a0!</em></p>\n<p>From my personal experience, focusing on specific, problematic queries that have a significant impact on execution time can lead to a significant improvement in performance. By targeting these queries, you can optimize the code and database structure, resulting in faster execution times and improved overall performance.</p>\n<h4>Let\u2019s see which all factors you can consider when deciding which queries to optimize:</h4>\n<ol><li>\n<strong>Queries that return a large number of rows:</strong> If a query returns a large number of rows, it can consume a lot of resources and cause performance issues. For example, a query that selects all records from a large table can be problematic.</li></ol>\n<pre>SELECT * FROM large_table;</pre>\n<p>2. <strong>Queries that use functions on columns: </strong>Functions on columns can prevent the use of indexes and slow down queries. For example, a query that uses the UPPER() function on a column can be problematic.</p>\n<pre>SELECT * FROM customers WHERE UPPER(name) = 'PARUL DHINGRA';</pre>\n<p>3. <strong>Queries that use JOINs with large tables: </strong>JOINs can be expensive operations, especially when they involve large tables. For example, a query that joins two tables with millions of rows can be problematic.</p>\n<pre>SELECT *<br>FROM orders<br>JOIN customers ON orders.customer_id = customers.customer_id;</pre>\n<p>4. <strong>Queries that use wildcard characters in LIKE clauses: </strong>LIKE clauses with wildcard characters can also prevent the use of indexes and slow down queries. For example, a query that searches for all records with a certain substring can be problematic.</p>\n<pre>SELECT * FROM customers WHERE name LIKE '%Doe%';</pre>\n<p>5. <strong>Queries that have multiple subqueries:</strong> Subqueries can be expensive operations, and queries with multiple subqueries can be especially problematic. For example, a query that uses multiple subqueries to calculate averages can be problematic.</p>\n<pre>SELECT *<br>FROM customers<br>WHERE age &gt; (SELECT AVG(age) FROM customers WHERE state = 'CA')<br>AND income &gt; (SELECT AVG(income) FROM customers WHERE state = 'CA');</pre>\n<p><strong>6. Queries that significantly contribute to the total execution time of a system: </strong>If larger percent of total execution time can be attributed to a single query, try to optimize that query instead. For example, a query that takes up <em>80% of the total execution time</em> may be a query that significantly contributes to performance issues. By optimizing these major contributors, you can use your time and resources more efficiently.</p>\n<p>Once you\u2019ve identified which queries need improvement, it\u2019s time to optimize them. So let\u2019s explore some effective strategies that I follow in my day-to-day work to improve the performance of SQL\u00a0queries.</p>\n<ol><li>\n<strong>Clarifying your requirements: </strong>Defining your requirements before constructing the query will enable you to obtain only the relevant information where you can narrow down the data fetched from the table during a query. Hence, increasing your query\u2019s speed and potentially decrease runtime, and optimize SQL\u00a0queries.</li></ol>\n<p><strong>2. Reduce Table Size: </strong>To ensure you only receive the information you need, you can filter your data by either of the below suitable\u00a0ways:</p>\n<p><strong>(i) Removing unused columns</strong>: If your table contains columns that are not frequently used or are no longer needed, removing them can help reduce the size of the table. Let\u2019s say you have a table called \u201ccustomers\u201d that contains several columns, including \u201cphone_number\u201d, \u201caddress\u201d, \u201cemail\u201d, and \u201clast_purchase_date\u201d. If you no longer need to store phone numbers for your customers, you can remove the \u201cphone_number\u201d column from the\u00a0table.</p>\n<p><strong>(ii) Limiting the dataset in a subquery:</strong></p>\n<p>For example, let\u2019s say you have a table called \u201cOrders\u201d that contains information about customer orders, including the order date, customer ID, and total order amount. You want to retrieve a list of customers who have placed at least one order in the last\u00a0month.</p>\n<p>You could use a subquery to limit the dataset to only orders that were placed within the last month, like\u00a0below:</p>\n<pre>SELECT customer_name<br>FROM customers<br>WHERE customer_id IN (<br>   SELECT customer_id<br>   FROM orders<br>   WHERE order_date &gt;= DATEADD(month, -1, GETDATE())<br>)</pre>\n<p>In this example, the subquery retrieves a list of customer IDs for orders that were placed within the last month. The main query then uses that list of customer IDs to retrieve the corresponding customer names from the \u201ccustomers\u201d table. By limiting the dataset in the subquery to only orders placed within the last month, the main query only retrieves data for customers who have placed recent orders, reducing the size of the resulting dataset.</p>\n<p><strong>(iii) Normalizing your data</strong>: Let\u2019s say you have a database with a table called \u201corders\u201d that contains information about customer orders, including the customer\u2019s name, address, and phone number, as well as the details of the order, such as the product name, quantity, and price. Instead of storing all of this information in a single table, you can normalize the data by splitting it into multiple\u00a0tables.</p>\n<p>For example, you can create a table called \u201c<strong>customers</strong>\u201d that contains the customer\u2019s name, address, and phone number. You can then create another table called \u201c<strong>products</strong>\u201d that contains information about the products, including the product name and price. Finally, you can create a table called \u201c<strong>order_items</strong>\u201d that contains the details of each order, including the product ID, quantity, and the order\u00a0ID.</p>\n<p>By normalizing the data in this way, you eliminate data duplication and reduce redundancy. For example, instead of storing the customer\u2019s name, address, and phone number for every order, you only store it once in the \u201ccustomers\u201d table. Similarly, the product details are stored only once in the \u201cproducts\u201d table, and the details of each order are stored in the \u201corder_items\u201d table. This can help improve performance and simplify queries, while also making it easier to maintain the\u00a0data.</p>\n<p><strong>(iv) Using data archiving:</strong> Let\u2019s say you have a database that contains customer order information from the past 5 years. However, you find that most of your queries are only concerned with data from the past year or two. To improve performance, you can use data archiving to move older data to a separate table or database.</p>\n<p>For example, you can create a new table called \u201corder_archive\u201d and move all orders that are more than 2 years old to this table. This will leave your main \u201corders\u201d table with only the most recent data, making it smaller and faster to query. You can also create an archive database and move the entire order archive table to this database, freeing up resources on your main database.</p>\n<p>You can still query the archived data if needed, but it will be stored separately from the main data and will not impact the performance of your frequently used queries. This can help improve query performance, reduce storage costs, and make it easier to manage your\u00a0data.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/300/1*RVquHtg3vR4wQ6idinZOOQ.png\"></figure><p>(v) <strong>Simplifying the JOINS in the queries: </strong>Sometimes, when a query joins tables, it drastically increases the result set\u2019s row count, which can lead to a slow execution time. Before joining tables, try to reduce their size, as explained above. When joining two tables, it is recommended to begin with the table that will produce the smallest set of results after applying\u00a0filters.</p>\n<p><strong>3. Consider using WHERE instead of HAVING</strong>: As most of you might be already aware, WHERE queries filter records before groups are created, while HAVING queries filter data <em>from groups</em>. Therefore, WHERE queries execute more quickly than HAVING\u00a0queries.</p>\n<p>Let\u2019s say you have a table called \u201corders\u201d that contains information about customer orders, including the customer ID, order ID, and the total cost of the order. You want to find the total cost of all orders for each customer that is greater than $1000. One way to do this is to use the HAVING\u00a0clause:</p>\n<pre>SELECT customer_id, SUM(total_cost) as total_spent<br>FROM orders<br>GROUP BY customer_id<br>HAVING SUM(total_cost) &gt; 1000;</pre>\n<p>SELECT customer_id, SUM(total_cost) as total_spent<br>FROM orders<br>GROUP BY customer_id<br>HAVING SUM(total_cost) &gt;\u00a01000;</p>\n<pre>SELECT customer_id, SUM(total_cost) as total_spent<br>FROM orders<br>WHERE total_cost &gt; 1000<br>GROUP BY customer_id;</pre>\n<p>This will return the same result, but it filters the data before grouping and aggregating it. The WHERE clause is applied before the GROUP BY clause, so only orders with a total cost greater than $1000 will be included in the calculation. This can be more efficient than using HAVING, especially if your table contains a large amount of data, because it reduces the amount of data that needs to be grouped and aggregated.</p>\n<p><strong>4. Use EXISTS() Instead of COUNT(): T</strong>o determine whether a table contains a specific record, using EXISTS() is generally more efficient than COUNT(). Unlike COUNT(), which searches the entire table to provide the total number of matching records, EXISTS() only needs to locate the first instance of the record in the table. This can save time and computing power, allowing you to optimize your SQL queries more effectively.</p>\n<p>Let\u2019s say you have two tables: \u201ccustomers\u201d and \u201corders\u201d. The \u201ccustomers\u201d table contains information about customers, including their ID and name. The \u201corders\u201d table contains information about customer orders, including the customer ID and the order ID. You want to find all customers who have placed an\u00a0order.</p>\n<p>One way to do this is to use the COUNT() function:</p>\n<pre>SELECT *<br>FROM customers<br>WHERE (SELECT COUNT(*) FROM orders WHERE orders.customer_id = customers.customer_id) &gt; 0;</pre>\n<p>This query uses a subquery to count the number of orders for each customer, and then filters the results to only include customers with at least one\u00a0order.</p>\n<p>However, a more efficient way to achieve the same result is to use the EXISTS() function:</p>\n<pre>SELECT *<br>FROM customers<br>WHERE EXISTS (SELECT 1 FROM orders WHERE orders.customer_id = customers.customer_id);</pre>\n<p>This query uses the EXISTS() function to check if there is at least one record in the \u201corders\u201d table that matches the customer ID in the \u201ccustomers\u201d table. The EXISTS() function is more efficient than COUNT() because it only needs to find one matching record, whereas COUNT() needs to count all records that match the condition. This can make a big difference in performance, especially if the tables contain a large amount of\u00a0data.</p>\n<p>5. <strong>Use SELECT Fields FROM Instead of SELECT * FROM\u00a0: </strong>As I mentioned above as well, the command SELECT * will fetch all the data from your table, whereas specifying fields can reduce query runtime by ensuring you only receive the necessary data.</p>\n<p>For example, if you want to find a specific user, the query SELECT DISTINCT Clara, Smith, Canada FROM Users might return several results, as many people in Canada are named Clara\u00a0Smith.</p>\n<p>Please note: SELECT DISTINCT relies on the <strong>GROUP BY</strong> clause, which requires a lot of processing power. To further filter your results and use less processing power, try SELECT ID, Clara, Smith, Canada, Manitoba, Winnipeg, R2C 0A1 FROM\u00a0Users.</p>\n<blockquote>\n<strong>Protip:</strong> When you insert <strong>EXPLAIN</strong> at the beginning of a query, you can locate and modify the most expensive steps. Then run <strong>EXPLAIN</strong> again to determine whether the changes you made significantly reduced runtime. However, running EXPLAIN takes time and computing power, so you should only use it during the MS SQL query optimization process.</blockquote>\n<p>6. <strong>Avoid Running Queries in a Loop: </strong>Running queries in a loop can significantly slow your runtime. In some cases, you may be able to bulk insert and update data, which is far more efficient than using\u00a0loops.</p>\n<p><strong>7. Create SQL Server Indexes: </strong>In addition to knowing how to properly create indexes, it\u2019s very important to understand when not to use\u00a0indexes.</p>\n<p>If you have an incredibly large range of values, it might be better to scan the whole table rather than use an index. In cases where functions or operations are applied to a column, you shouldn\u2019t use indexes. You should also evaluate your existing\u00a0indexes.</p>\n<p>So, now don\u2019t let slow SQL queries hold you back any\u00a0longer.</p>\n<p>With these proven methods in your toolkit, you can optimize your database, improve query performance, and supercharge your productivity. So what are you waiting for?\u00a0?</p>\n<p>Go and start implementing these techniques from today itself and unlock the full potential of your\u00a0data!</p>\n<p>Thank me later\u00a0;)</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d9d18260aa6b\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/841/1*3GQy18iMCxegCVul6AQrXg.png\"></figure><p>Before you optimize your queries, you have to decide which ones are best to optimize. If you are less selective when deciding which queries to optimize, you may end up wasting time and money by optimizing those that don\u2019t significantly contribute to performance, don\u2019t impact other queries, or don\u2019t result in problems users will\u00a0notice.</p>\n<p><em>Unfortunately, many people skip this critical step\u00a0!\u00a0!</em></p>\n<p>From my personal experience, focusing on specific, problematic queries that have a significant impact on execution time can lead to a significant improvement in performance. By targeting these queries, you can optimize the code and database structure, resulting in faster execution times and improved overall performance.</p>\n<h4>Let\u2019s see which all factors you can consider when deciding which queries to optimize:</h4>\n<ol><li>\n<strong>Queries that return a large number of rows:</strong> If a query returns a large number of rows, it can consume a lot of resources and cause performance issues. For example, a query that selects all records from a large table can be problematic.</li></ol>\n<pre>SELECT * FROM large_table;</pre>\n<p>2. <strong>Queries that use functions on columns: </strong>Functions on columns can prevent the use of indexes and slow down queries. For example, a query that uses the UPPER() function on a column can be problematic.</p>\n<pre>SELECT * FROM customers WHERE UPPER(name) = 'PARUL DHINGRA';</pre>\n<p>3. <strong>Queries that use JOINs with large tables: </strong>JOINs can be expensive operations, especially when they involve large tables. For example, a query that joins two tables with millions of rows can be problematic.</p>\n<pre>SELECT *<br>FROM orders<br>JOIN customers ON orders.customer_id = customers.customer_id;</pre>\n<p>4. <strong>Queries that use wildcard characters in LIKE clauses: </strong>LIKE clauses with wildcard characters can also prevent the use of indexes and slow down queries. For example, a query that searches for all records with a certain substring can be problematic.</p>\n<pre>SELECT * FROM customers WHERE name LIKE '%Doe%';</pre>\n<p>5. <strong>Queries that have multiple subqueries:</strong> Subqueries can be expensive operations, and queries with multiple subqueries can be especially problematic. For example, a query that uses multiple subqueries to calculate averages can be problematic.</p>\n<pre>SELECT *<br>FROM customers<br>WHERE age &gt; (SELECT AVG(age) FROM customers WHERE state = 'CA')<br>AND income &gt; (SELECT AVG(income) FROM customers WHERE state = 'CA');</pre>\n<p><strong>6. Queries that significantly contribute to the total execution time of a system: </strong>If larger percent of total execution time can be attributed to a single query, try to optimize that query instead. For example, a query that takes up <em>80% of the total execution time</em> may be a query that significantly contributes to performance issues. By optimizing these major contributors, you can use your time and resources more efficiently.</p>\n<p>Once you\u2019ve identified which queries need improvement, it\u2019s time to optimize them. So let\u2019s explore some effective strategies that I follow in my day-to-day work to improve the performance of SQL\u00a0queries.</p>\n<ol><li>\n<strong>Clarifying your requirements: </strong>Defining your requirements before constructing the query will enable you to obtain only the relevant information where you can narrow down the data fetched from the table during a query. Hence, increasing your query\u2019s speed and potentially decrease runtime, and optimize SQL\u00a0queries.</li></ol>\n<p><strong>2. Reduce Table Size: </strong>To ensure you only receive the information you need, you can filter your data by either of the below suitable\u00a0ways:</p>\n<p><strong>(i) Removing unused columns</strong>: If your table contains columns that are not frequently used or are no longer needed, removing them can help reduce the size of the table. Let\u2019s say you have a table called \u201ccustomers\u201d that contains several columns, including \u201cphone_number\u201d, \u201caddress\u201d, \u201cemail\u201d, and \u201clast_purchase_date\u201d. If you no longer need to store phone numbers for your customers, you can remove the \u201cphone_number\u201d column from the\u00a0table.</p>\n<p><strong>(ii) Limiting the dataset in a subquery:</strong></p>\n<p>For example, let\u2019s say you have a table called \u201cOrders\u201d that contains information about customer orders, including the order date, customer ID, and total order amount. You want to retrieve a list of customers who have placed at least one order in the last\u00a0month.</p>\n<p>You could use a subquery to limit the dataset to only orders that were placed within the last month, like\u00a0below:</p>\n<pre>SELECT customer_name<br>FROM customers<br>WHERE customer_id IN (<br>   SELECT customer_id<br>   FROM orders<br>   WHERE order_date &gt;= DATEADD(month, -1, GETDATE())<br>)</pre>\n<p>In this example, the subquery retrieves a list of customer IDs for orders that were placed within the last month. The main query then uses that list of customer IDs to retrieve the corresponding customer names from the \u201ccustomers\u201d table. By limiting the dataset in the subquery to only orders placed within the last month, the main query only retrieves data for customers who have placed recent orders, reducing the size of the resulting dataset.</p>\n<p><strong>(iii) Normalizing your data</strong>: Let\u2019s say you have a database with a table called \u201corders\u201d that contains information about customer orders, including the customer\u2019s name, address, and phone number, as well as the details of the order, such as the product name, quantity, and price. Instead of storing all of this information in a single table, you can normalize the data by splitting it into multiple\u00a0tables.</p>\n<p>For example, you can create a table called \u201c<strong>customers</strong>\u201d that contains the customer\u2019s name, address, and phone number. You can then create another table called \u201c<strong>products</strong>\u201d that contains information about the products, including the product name and price. Finally, you can create a table called \u201c<strong>order_items</strong>\u201d that contains the details of each order, including the product ID, quantity, and the order\u00a0ID.</p>\n<p>By normalizing the data in this way, you eliminate data duplication and reduce redundancy. For example, instead of storing the customer\u2019s name, address, and phone number for every order, you only store it once in the \u201ccustomers\u201d table. Similarly, the product details are stored only once in the \u201cproducts\u201d table, and the details of each order are stored in the \u201corder_items\u201d table. This can help improve performance and simplify queries, while also making it easier to maintain the\u00a0data.</p>\n<p><strong>(iv) Using data archiving:</strong> Let\u2019s say you have a database that contains customer order information from the past 5 years. However, you find that most of your queries are only concerned with data from the past year or two. To improve performance, you can use data archiving to move older data to a separate table or database.</p>\n<p>For example, you can create a new table called \u201corder_archive\u201d and move all orders that are more than 2 years old to this table. This will leave your main \u201corders\u201d table with only the most recent data, making it smaller and faster to query. You can also create an archive database and move the entire order archive table to this database, freeing up resources on your main database.</p>\n<p>You can still query the archived data if needed, but it will be stored separately from the main data and will not impact the performance of your frequently used queries. This can help improve query performance, reduce storage costs, and make it easier to manage your\u00a0data.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/300/1*RVquHtg3vR4wQ6idinZOOQ.png\"></figure><p>(v) <strong>Simplifying the JOINS in the queries: </strong>Sometimes, when a query joins tables, it drastically increases the result set\u2019s row count, which can lead to a slow execution time. Before joining tables, try to reduce their size, as explained above. When joining two tables, it is recommended to begin with the table that will produce the smallest set of results after applying\u00a0filters.</p>\n<p><strong>3. Consider using WHERE instead of HAVING</strong>: As most of you might be already aware, WHERE queries filter records before groups are created, while HAVING queries filter data <em>from groups</em>. Therefore, WHERE queries execute more quickly than HAVING\u00a0queries.</p>\n<p>Let\u2019s say you have a table called \u201corders\u201d that contains information about customer orders, including the customer ID, order ID, and the total cost of the order. You want to find the total cost of all orders for each customer that is greater than $1000. One way to do this is to use the HAVING\u00a0clause:</p>\n<pre>SELECT customer_id, SUM(total_cost) as total_spent<br>FROM orders<br>GROUP BY customer_id<br>HAVING SUM(total_cost) &gt; 1000;</pre>\n<p>SELECT customer_id, SUM(total_cost) as total_spent<br>FROM orders<br>GROUP BY customer_id<br>HAVING SUM(total_cost) &gt;\u00a01000;</p>\n<pre>SELECT customer_id, SUM(total_cost) as total_spent<br>FROM orders<br>WHERE total_cost &gt; 1000<br>GROUP BY customer_id;</pre>\n<p>This will return the same result, but it filters the data before grouping and aggregating it. The WHERE clause is applied before the GROUP BY clause, so only orders with a total cost greater than $1000 will be included in the calculation. This can be more efficient than using HAVING, especially if your table contains a large amount of data, because it reduces the amount of data that needs to be grouped and aggregated.</p>\n<p><strong>4. Use EXISTS() Instead of COUNT(): T</strong>o determine whether a table contains a specific record, using EXISTS() is generally more efficient than COUNT(). Unlike COUNT(), which searches the entire table to provide the total number of matching records, EXISTS() only needs to locate the first instance of the record in the table. This can save time and computing power, allowing you to optimize your SQL queries more effectively.</p>\n<p>Let\u2019s say you have two tables: \u201ccustomers\u201d and \u201corders\u201d. The \u201ccustomers\u201d table contains information about customers, including their ID and name. The \u201corders\u201d table contains information about customer orders, including the customer ID and the order ID. You want to find all customers who have placed an\u00a0order.</p>\n<p>One way to do this is to use the COUNT() function:</p>\n<pre>SELECT *<br>FROM customers<br>WHERE (SELECT COUNT(*) FROM orders WHERE orders.customer_id = customers.customer_id) &gt; 0;</pre>\n<p>This query uses a subquery to count the number of orders for each customer, and then filters the results to only include customers with at least one\u00a0order.</p>\n<p>However, a more efficient way to achieve the same result is to use the EXISTS() function:</p>\n<pre>SELECT *<br>FROM customers<br>WHERE EXISTS (SELECT 1 FROM orders WHERE orders.customer_id = customers.customer_id);</pre>\n<p>This query uses the EXISTS() function to check if there is at least one record in the \u201corders\u201d table that matches the customer ID in the \u201ccustomers\u201d table. The EXISTS() function is more efficient than COUNT() because it only needs to find one matching record, whereas COUNT() needs to count all records that match the condition. This can make a big difference in performance, especially if the tables contain a large amount of\u00a0data.</p>\n<p>5. <strong>Use SELECT Fields FROM Instead of SELECT * FROM\u00a0: </strong>As I mentioned above as well, the command SELECT * will fetch all the data from your table, whereas specifying fields can reduce query runtime by ensuring you only receive the necessary data.</p>\n<p>For example, if you want to find a specific user, the query SELECT DISTINCT Clara, Smith, Canada FROM Users might return several results, as many people in Canada are named Clara\u00a0Smith.</p>\n<p>Please note: SELECT DISTINCT relies on the <strong>GROUP BY</strong> clause, which requires a lot of processing power. To further filter your results and use less processing power, try SELECT ID, Clara, Smith, Canada, Manitoba, Winnipeg, R2C 0A1 FROM\u00a0Users.</p>\n<blockquote>\n<strong>Protip:</strong> When you insert <strong>EXPLAIN</strong> at the beginning of a query, you can locate and modify the most expensive steps. Then run <strong>EXPLAIN</strong> again to determine whether the changes you made significantly reduced runtime. However, running EXPLAIN takes time and computing power, so you should only use it during the MS SQL query optimization process.</blockquote>\n<p>6. <strong>Avoid Running Queries in a Loop: </strong>Running queries in a loop can significantly slow your runtime. In some cases, you may be able to bulk insert and update data, which is far more efficient than using\u00a0loops.</p>\n<p><strong>7. Create SQL Server Indexes: </strong>In addition to knowing how to properly create indexes, it\u2019s very important to understand when not to use\u00a0indexes.</p>\n<p>If you have an incredibly large range of values, it might be better to scan the whole table rather than use an index. In cases where functions or operations are applied to a column, you shouldn\u2019t use indexes. You should also evaluate your existing\u00a0indexes.</p>\n<p>So, now don\u2019t let slow SQL queries hold you back any\u00a0longer.</p>\n<p>With these proven methods in your toolkit, you can optimize your database, improve query performance, and supercharge your productivity. So what are you waiting for?\u00a0?</p>\n<p>Go and start implementing these techniques from today itself and unlock the full potential of your\u00a0data!</p>\n<p>Thank me later\u00a0;)</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d9d18260aa6b\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["software-development","sql","performance","database","backend"]},{"title":"Recovering From Common Git Errors","pubDate":"2022-06-27 17:23:08","link":"https://betterprogramming.pub/recovering-from-common-git-errors-eccda7ec6180?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/eccda7ec6180","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/777/1*NGwbJd4VYjeYYLXLJxbDCQ.png","description":"\n<h4>To get back to your development faster</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/777/1*NGwbJd4VYjeYYLXLJxbDCQ.png\"></figure><p>We often come across some common errors when working with something as intricate as Git. But as humans, we\u2019re going to make mistakes and after all, the most effective way of learning is from a\u00a0mistake.</p>\n<p>So, instead of panicking and without any further ado, here I am sharing all those git mistakes I made and how I fixed those mistakes.</p>\n<h3>Error 1: Inadvertently Deleted a\u00a0Branch</h3>\n<p>So, there can be two scenarios: either you realize the mistake right away(i.e., instead of the intended one, deleted another branch) or you don\u2019t realize initially that you deleted the wrong branch but later you realize\u00a0it.</p>\n<p>In the first scenario, you can simply check the message in the terminal after the deletion of the branch. It may look something like\u00a0this:</p>\n<pre>$git branch -d branch1<br>warning: deleting branch 'branch1' that has been merged to 'refs/remotes/origin/branch1', but not yet merged to HEAD.<br>Deleted branch branch1(was e9498ae).</pre>\n<p>Here, we see the SHA value of the commit to which the branch pointed when it was deleted. Using this SHA value we can create a new branch from that commit itself. You just need to do the following:</p>\n<p>git checkout\u00a0[SHA]</p>\n<p>And once you're at that commit, you can recreate the branch from there by\u00a0using:</p>\n<p>git checkout -b [branchname]</p>\n<p>In the second case, if you\u2019ve lost the message, to find the SHA of the commit that was at the tip of the deleted branch. Do git reflog, which is actually the record of all commits that are or were referenced in your repo at any\u00a0time.</p>\n<p>Then, to proceed, you may perform the same commands as mentioned in the first case\u00a0above.</p>\n<h3>Error 2: You Deleted a File or Directory</h3>\n<p>Here\u2019s a scenario we all\u00a0dread!</p>\n<p>All of us have definitely deleted the wrong file from our project at least once. It can either be an abruptly executed rm -rf command, or an absent-minded select and delete, or maybe the result of any erroneous script!</p>\n<p>Whatever the reason, deleting an important file can be exasperating if not fixed immediately.</p>\n<p>Again, there can be many possible scenarios:</p>\n<ol><li>If you immediately realized it was a mistake, you need to run the following command:</li></ol>\n<p>$ git checkout HEAD &lt;filename&gt;</p>\n<p>2. Or, another case can be you deleted the file and committed the deletion as well. The following command will take you back to the state before your\u00a0commit.</p>\n<p>So, there\u2019re three ways you can do\u00a0so:</p>\n<p>$ git reset --soft\u00a0HEAD~1</p>\n<p>Here, we\u2019re saying let\u2019s roll back in time, but let\u2019s hold onto those changes and let\u2019s keep them in the staging area and in the working directory as if they\u2019re just not committed yet. It\u2019s a little bit similar to git commit\u00a0amend.</p>\n<p>$ git reset --mixed\u00a0HEAD~1</p>\n<p>A mixed reset allows us to return to an old state, just like a soft reset does, and it leaves code changes in the working directory but not in the staging\u00a0area.</p>\n<p>$ git reset --hard\u00a0HEAD~1</p>\n<p>Now the head pointer is pointing back to one commit, just like the other ones did. But, if you\u2019ll get the status, your changes aren\u2019t there. They\u2019re just\u00a0gone!</p>\n<p>Using hard reset, git doesn\u2019t try to keep track of them. It doesn\u2019t put them in my staging area or my working directory. It just says, \u201cyou know what, forget about\u00a0them.\u201d</p>\n<p>3. Now, let\u2019s deal with the scenario where you committed the deletion and then did more\u00a0commits.</p>\n<p>First, to find the right commit, check the history for the deleted\u00a0file:</p>\n<p>$ git log -- &lt;filename&gt;</p>\n<p>You can either work with the last commit that still had the file or the commit that deleted the file. In the first case, just check out the file from that\u00a0commit:</p>\n<pre>$ git checkout &lt;commit hash&gt; -- &lt;filename&gt;</pre>\n<p>In the second case, check out the file from one commit before\u00a0that:</p>\n<pre>$ git checkout &lt;deletion commit hash&gt;~1 -- &lt;filename&gt;</pre>\n<p>4. Another possible mistake we make is that we deleted a file, committed it, and pushed\u00a0it.</p>\n<p>If you\u2019ve already pushed your commit or commits to a remote, resetting and pushing again will cause problems, as the history of the local repository has essentially been rewritten. In this case, it is probably better to record a new commit that undoes the work of the one deleting the file. To do this, run the following command:</p>\n<pre>$ git revert --no-commit &lt;commit&gt;</pre>\n<p>Above, &lt;commit&gt; is the commit deleting the file. Following this, create your new commit as desired. The \u201c\u2014 no-commit option prevents the command from creating a new commit right away, instead of allowing you to choose exactly which of the changes introduced in the old commit you want to revert in your new\u00a0commit.</p>\n<h3>Error 3: You Added a File You Didn\u2019t Want in the\u00a0Repo</h3>\n<p>Damn! I recently faced this issue, and it\u2019s a\u00a0pain!</p>\n<p>I accidentally pushed the file, and I just don\u2019t want it there anymore. So, this is the command you can use to delete a file from your git\u00a0repo:</p>\n<pre>git rm --cached &lt;filename&gt;</pre>\n<p>This will not delete it locally, so it is safe on your computer if you want to keep it in there for reference without sharing it on\u00a0Git.</p>\n<p><strong>Note</strong>: To prevent it from being pushed to Git again, just add the file to your\u00a0.gitignore.</p>\n<p>Of course, if you just don\u2019t need the file anymore at all, simply delete it from your system as\u00a0well.</p>\n<p>Wait!</p>\n<p>But what if the file had sensitive data like passwords or secret\u00a0keys?</p>\n<p>As you might be aware, the commits can still be found in the repository\u2019s history. So, apart from this, you\u2019ll need to do a little bit\u00a0more.</p>\n<h4>If the pushed file has sensitive data like passwords</h4>\n<p>The above method will not completely remove the file from the commit\u00a0history.</p>\n<p>To remove the sensitive file from your history as well, you can use an open source tool called the <a href=\"https://rtyley.github.io/bfg-repo-cleaner/\">BFG Repo-Cleaner</a> or use git\u2019s git filter-branch.</p>\n<p>BFG Repo-Cleaner makes it much easier and faster to get the job done as compared to filter-branch. It allows you to delete files or, alternatively, replace the passwords or keys within the file with the text ***REMOVED***. You can also remove huge files that you accidentally pushed.</p>\n<p>You can check out <a href=\"https://rtyley.github.io/bfg-repo-cleaner/\">BFG Repo-Cleaner\u2019s documentation and download page</a> to see how to use it. The instructions are pretty forthright.</p>\n<p>Also, to learn about the git filter-branch, check out git's <a href=\"https://help.github.com/en/articles/removing-sensitive-data-from-a-repository#using-filter-branch\">Using filter-branch</a> article on their help site and the <a href=\"https://git-scm.com/docs/git-filter-branch\">git filter-branch documentation</a>.</p>\n<h3>Error #4: You Forgot to Add a File to That Last\u00a0Commit</h3>\n<p>Another common Git pitfall is committing too\u00a0early.</p>\n<p>You missed a file, forgot to save it, or need to make a minor change for the last commit to make sense. --amend is your best\u00a0friend.</p>\n<p>Add that missed file and then run that trusty\u00a0command:</p>\n<pre>git add missed-file.txt<br>git commit --amend</pre>\n<p>At this point, you can either amend the commit message or just save it to keep it the\u00a0same.</p>\n<p>So, these were some common fixes to get out of the most common Git\u00a0errors.</p>\n<p>If you have some git tips of your own, let me know in the comments below, I\u2019d love to hear\u00a0them.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=eccda7ec6180\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://betterprogramming.pub/recovering-from-common-git-errors-eccda7ec6180\">Recovering From Common Git Errors</a> was originally published in <a href=\"https://betterprogramming.pub/\">Better Programming</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n","content":"\n<h4>To get back to your development faster</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/777/1*NGwbJd4VYjeYYLXLJxbDCQ.png\"></figure><p>We often come across some common errors when working with something as intricate as Git. But as humans, we\u2019re going to make mistakes and after all, the most effective way of learning is from a\u00a0mistake.</p>\n<p>So, instead of panicking and without any further ado, here I am sharing all those git mistakes I made and how I fixed those mistakes.</p>\n<h3>Error 1: Inadvertently Deleted a\u00a0Branch</h3>\n<p>So, there can be two scenarios: either you realize the mistake right away(i.e., instead of the intended one, deleted another branch) or you don\u2019t realize initially that you deleted the wrong branch but later you realize\u00a0it.</p>\n<p>In the first scenario, you can simply check the message in the terminal after the deletion of the branch. It may look something like\u00a0this:</p>\n<pre>$git branch -d branch1<br>warning: deleting branch 'branch1' that has been merged to 'refs/remotes/origin/branch1', but not yet merged to HEAD.<br>Deleted branch branch1(was e9498ae).</pre>\n<p>Here, we see the SHA value of the commit to which the branch pointed when it was deleted. Using this SHA value we can create a new branch from that commit itself. You just need to do the following:</p>\n<p>git checkout\u00a0[SHA]</p>\n<p>And once you're at that commit, you can recreate the branch from there by\u00a0using:</p>\n<p>git checkout -b [branchname]</p>\n<p>In the second case, if you\u2019ve lost the message, to find the SHA of the commit that was at the tip of the deleted branch. Do git reflog, which is actually the record of all commits that are or were referenced in your repo at any\u00a0time.</p>\n<p>Then, to proceed, you may perform the same commands as mentioned in the first case\u00a0above.</p>\n<h3>Error 2: You Deleted a File or Directory</h3>\n<p>Here\u2019s a scenario we all\u00a0dread!</p>\n<p>All of us have definitely deleted the wrong file from our project at least once. It can either be an abruptly executed rm -rf command, or an absent-minded select and delete, or maybe the result of any erroneous script!</p>\n<p>Whatever the reason, deleting an important file can be exasperating if not fixed immediately.</p>\n<p>Again, there can be many possible scenarios:</p>\n<ol><li>If you immediately realized it was a mistake, you need to run the following command:</li></ol>\n<p>$ git checkout HEAD &lt;filename&gt;</p>\n<p>2. Or, another case can be you deleted the file and committed the deletion as well. The following command will take you back to the state before your\u00a0commit.</p>\n<p>So, there\u2019re three ways you can do\u00a0so:</p>\n<p>$ git reset --soft\u00a0HEAD~1</p>\n<p>Here, we\u2019re saying let\u2019s roll back in time, but let\u2019s hold onto those changes and let\u2019s keep them in the staging area and in the working directory as if they\u2019re just not committed yet. It\u2019s a little bit similar to git commit\u00a0amend.</p>\n<p>$ git reset --mixed\u00a0HEAD~1</p>\n<p>A mixed reset allows us to return to an old state, just like a soft reset does, and it leaves code changes in the working directory but not in the staging\u00a0area.</p>\n<p>$ git reset --hard\u00a0HEAD~1</p>\n<p>Now the head pointer is pointing back to one commit, just like the other ones did. But, if you\u2019ll get the status, your changes aren\u2019t there. They\u2019re just\u00a0gone!</p>\n<p>Using hard reset, git doesn\u2019t try to keep track of them. It doesn\u2019t put them in my staging area or my working directory. It just says, \u201cyou know what, forget about\u00a0them.\u201d</p>\n<p>3. Now, let\u2019s deal with the scenario where you committed the deletion and then did more\u00a0commits.</p>\n<p>First, to find the right commit, check the history for the deleted\u00a0file:</p>\n<p>$ git log -- &lt;filename&gt;</p>\n<p>You can either work with the last commit that still had the file or the commit that deleted the file. In the first case, just check out the file from that\u00a0commit:</p>\n<pre>$ git checkout &lt;commit hash&gt; -- &lt;filename&gt;</pre>\n<p>In the second case, check out the file from one commit before\u00a0that:</p>\n<pre>$ git checkout &lt;deletion commit hash&gt;~1 -- &lt;filename&gt;</pre>\n<p>4. Another possible mistake we make is that we deleted a file, committed it, and pushed\u00a0it.</p>\n<p>If you\u2019ve already pushed your commit or commits to a remote, resetting and pushing again will cause problems, as the history of the local repository has essentially been rewritten. In this case, it is probably better to record a new commit that undoes the work of the one deleting the file. To do this, run the following command:</p>\n<pre>$ git revert --no-commit &lt;commit&gt;</pre>\n<p>Above, &lt;commit&gt; is the commit deleting the file. Following this, create your new commit as desired. The \u201c\u2014 no-commit option prevents the command from creating a new commit right away, instead of allowing you to choose exactly which of the changes introduced in the old commit you want to revert in your new\u00a0commit.</p>\n<h3>Error 3: You Added a File You Didn\u2019t Want in the\u00a0Repo</h3>\n<p>Damn! I recently faced this issue, and it\u2019s a\u00a0pain!</p>\n<p>I accidentally pushed the file, and I just don\u2019t want it there anymore. So, this is the command you can use to delete a file from your git\u00a0repo:</p>\n<pre>git rm --cached &lt;filename&gt;</pre>\n<p>This will not delete it locally, so it is safe on your computer if you want to keep it in there for reference without sharing it on\u00a0Git.</p>\n<p><strong>Note</strong>: To prevent it from being pushed to Git again, just add the file to your\u00a0.gitignore.</p>\n<p>Of course, if you just don\u2019t need the file anymore at all, simply delete it from your system as\u00a0well.</p>\n<p>Wait!</p>\n<p>But what if the file had sensitive data like passwords or secret\u00a0keys?</p>\n<p>As you might be aware, the commits can still be found in the repository\u2019s history. So, apart from this, you\u2019ll need to do a little bit\u00a0more.</p>\n<h4>If the pushed file has sensitive data like passwords</h4>\n<p>The above method will not completely remove the file from the commit\u00a0history.</p>\n<p>To remove the sensitive file from your history as well, you can use an open source tool called the <a href=\"https://rtyley.github.io/bfg-repo-cleaner/\">BFG Repo-Cleaner</a> or use git\u2019s git filter-branch.</p>\n<p>BFG Repo-Cleaner makes it much easier and faster to get the job done as compared to filter-branch. It allows you to delete files or, alternatively, replace the passwords or keys within the file with the text ***REMOVED***. You can also remove huge files that you accidentally pushed.</p>\n<p>You can check out <a href=\"https://rtyley.github.io/bfg-repo-cleaner/\">BFG Repo-Cleaner\u2019s documentation and download page</a> to see how to use it. The instructions are pretty forthright.</p>\n<p>Also, to learn about the git filter-branch, check out git's <a href=\"https://help.github.com/en/articles/removing-sensitive-data-from-a-repository#using-filter-branch\">Using filter-branch</a> article on their help site and the <a href=\"https://git-scm.com/docs/git-filter-branch\">git filter-branch documentation</a>.</p>\n<h3>Error #4: You Forgot to Add a File to That Last\u00a0Commit</h3>\n<p>Another common Git pitfall is committing too\u00a0early.</p>\n<p>You missed a file, forgot to save it, or need to make a minor change for the last commit to make sense. --amend is your best\u00a0friend.</p>\n<p>Add that missed file and then run that trusty\u00a0command:</p>\n<pre>git add missed-file.txt<br>git commit --amend</pre>\n<p>At this point, you can either amend the commit message or just save it to keep it the\u00a0same.</p>\n<p>So, these were some common fixes to get out of the most common Git\u00a0errors.</p>\n<p>If you have some git tips of your own, let me know in the comments below, I\u2019d love to hear\u00a0them.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=eccda7ec6180\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://betterprogramming.pub/recovering-from-common-git-errors-eccda7ec6180\">Recovering From Common Git Errors</a> was originally published in <a href=\"https://betterprogramming.pub/\">Better Programming</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n","enclosure":{},"categories":["programming","coding","software-engineering","git","software-development"]},{"title":"How to Delete Child Records in OneToMany Relationship From Database in JPA?","pubDate":"2021-09-21 13:51:51","link":"https://betterprogramming.pub/how-to-delete-child-records-in-onetomany-relationship-from-database-in-jpa-38d78e02d7a1?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/38d78e02d7a1","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/2600/0*mMKxr0bkxrUN_kSC","description":"<div class=\"medium-feed-item\">\n<p class=\"medium-feed-image\"><a href=\"https://betterprogramming.pub/how-to-delete-child-records-in-onetomany-relationship-from-database-in-jpa-38d78e02d7a1?source=rss-6e9b39ccfd81------2\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*mMKxr0bkxrUN_kSC\" width=\"4912\"></a></p>\n<p class=\"medium-feed-snippet\">Can Hibernate automatically delete the child entity if I remove its association to the parent? Let\u2019s find out</p>\n<p class=\"medium-feed-link\"><a href=\"https://betterprogramming.pub/how-to-delete-child-records-in-onetomany-relationship-from-database-in-jpa-38d78e02d7a1?source=rss-6e9b39ccfd81------2\">Continue reading on Better Programming \u00bb</a></p>\n</div>","content":"<div class=\"medium-feed-item\">\n<p class=\"medium-feed-image\"><a href=\"https://betterprogramming.pub/how-to-delete-child-records-in-onetomany-relationship-from-database-in-jpa-38d78e02d7a1?source=rss-6e9b39ccfd81------2\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*mMKxr0bkxrUN_kSC\" width=\"4912\"></a></p>\n<p class=\"medium-feed-snippet\">Can Hibernate automatically delete the child entity if I remove its association to the parent? Let\u2019s find out</p>\n<p class=\"medium-feed-link\"><a href=\"https://betterprogramming.pub/how-to-delete-child-records-in-onetomany-relationship-from-database-in-jpa-38d78e02d7a1?source=rss-6e9b39ccfd81------2\">Continue reading on Better Programming \u00bb</a></p>\n</div>","enclosure":{},"categories":["spring-boot","java","programming","software-development","web-development"]},{"title":"Avoid Security Loopholes Using @JsonView in Spring Boot","pubDate":"2020-10-15 01:13:13","link":"https://betterprogramming.pub/avoid-security-loopholes-using-jsonview-in-spring-boot-3b1230f1ae30?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/3b1230f1ae30","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/1024/1*Brx6zWxETsJqFTBmJyr5TQ.png","description":"\n<h4>Don\u2019t expose more than you think needs\u00a0exposing</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Brx6zWxETsJqFTBmJyr5TQ.png\"><figcaption>Spring Boot\u00a0logo</figcaption></figure><p>If a certain property on an object is internal to your business and not useful to a consumer, then don\u2019t return\u00a0it.</p>\n<p>Let\u2019s say we\u2019re using the controller to query information and return it to the front end in the JSON data format. Often, some username and password queries are involved in the JSON data, but for security reasons, we may not need all of the User object user information (for example, username and password) to be returned to the front\u00a0end.</p>\n<p>But when we use the <a href=\"http://twitter.com/RestController\">@RestController</a> annotation, the returned User object is automatically converted to the corresponding JSON array and transmitted to the front end. We can\u2019t remove the unnecessary JSON information, such as the username and password, and then return it. In order to solve this JSON data-control problem, we can use the JsonView annotation for development.</p>\n<h3>Let\u2019s Learn With an\u00a0Example</h3>\n<p>Sometimes you may want to reuse the same form class for receiving request data in multiple handlers/controllers.</p>\n<p>For example, say you have this UserForm for user registration:</p>\n<pre>public class UserForm {<br><br>  private String username;<br><br>  private String name;<br><br>  private String password;<br><br>  // Getters and Setters ...<br>}</pre>\n<p>The user-registration handler looks like the following:</p>\n<pre>@PostMapping(\"/users\")<br>@ResponseStatus(HttpStatus.CREATED)<br>public UserDto signup(@RequestBody UserForm userForm){<br>    return userService.signup(userForm);<br>}</pre>\n<p>Now, say you have another handler for updating users, looking like\u00a0this:</p>\n<pre>@PutMapping(\"/users/{id}\")<br>public UserDto updateUser(@pathVariable long id, @RequestBody UserForm userForm) {<br><br>  return userService.update(id, userForm);<br>}</pre>\n<p>Notice the same userForm<strong>\u00a0</strong>above?</p>\n<p>Consequently, someone can call the endpoint with the unrequired fields (e.g., username and password), thus injecting those into your\u00a0form.</p>\n<p>This is where the @JsonView annotation could be really useful. You can define @JsonView on fields that need to be included in the API response.</p>\n<p>But the question is: Gow do we inform the Jackson processor to consider only certain fields based on the\u00a0API?</p>\n<h3>How to Use @JsonView</h3>\n<p>We can use @JsonView to limit or control-field display for different users. You can decide which properties to be serialized based on the View class provided in the JsonView annotation. Sounds interesting, right?</p>\n<p>To prevent the kind of injection discussed above, first define a marker interface, as\u00a0below:</p>\n<pre>public interface UpdateUser {}</pre>\n<p>Then, in userForm<strong>, </strong>annotate the fields you want to receive when updating with @JsonView(UpdateUser.class):</p>\n<pre>public class UserForm {<br><br>  private String username;<br><br>  @JsonView(UpdateUser.class)<br>  private String name;<br><br>  private String password;<br><br>  // Getters and Setters ...<br>}</pre>\n<p>Now our model is ready, but this isn\u2019t enough. We should make sure our REST API methods are annotated with @JsonView, as shown below. So finally, use the same annotation in the handler, as\u00a0below:</p>\n<pre>@PutMapping(\"/users/{id}\")<br>public UserDto updateUser(@pathVariable long id,<br>  @RequestBody @JsonView(UpdateUser.class) UserForm userForm) {<br><br>   return userService.update(id, userForm);<br>}</pre>\n<p>That\u2019s all you need to prevent the injection.</p>\n<h3>Conclusion</h3>\n<p>This is very useful, particularly when you\u2019re reusing the domain classes as forms. For example, if you reuse a User domain class as the form and then save it straight to the database, you can get hacked, and this is where the real trouble comes\u00a0in.</p>\n<p>When registering, what if a malicious user adds an id or a createdDate field, that gets injected instead of autogenerated?</p>\n<p>Take a few minutes and ponder over the question before you jump to a conclusion.</p>\n<p>I hope you learned something from this article. Also please share if there are better alternatives. See you in another article\u00a0soon.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3b1230f1ae30\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://betterprogramming.pub/avoid-security-loopholes-using-jsonview-in-spring-boot-3b1230f1ae30\">Avoid Security Loopholes Using @JsonView in Spring Boot</a> was originally published in <a href=\"https://betterprogramming.pub/\">Better Programming</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n","content":"\n<h4>Don\u2019t expose more than you think needs\u00a0exposing</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Brx6zWxETsJqFTBmJyr5TQ.png\"><figcaption>Spring Boot\u00a0logo</figcaption></figure><p>If a certain property on an object is internal to your business and not useful to a consumer, then don\u2019t return\u00a0it.</p>\n<p>Let\u2019s say we\u2019re using the controller to query information and return it to the front end in the JSON data format. Often, some username and password queries are involved in the JSON data, but for security reasons, we may not need all of the User object user information (for example, username and password) to be returned to the front\u00a0end.</p>\n<p>But when we use the <a href=\"http://twitter.com/RestController\">@RestController</a> annotation, the returned User object is automatically converted to the corresponding JSON array and transmitted to the front end. We can\u2019t remove the unnecessary JSON information, such as the username and password, and then return it. In order to solve this JSON data-control problem, we can use the JsonView annotation for development.</p>\n<h3>Let\u2019s Learn With an\u00a0Example</h3>\n<p>Sometimes you may want to reuse the same form class for receiving request data in multiple handlers/controllers.</p>\n<p>For example, say you have this UserForm for user registration:</p>\n<pre>public class UserForm {<br><br>  private String username;<br><br>  private String name;<br><br>  private String password;<br><br>  // Getters and Setters ...<br>}</pre>\n<p>The user-registration handler looks like the following:</p>\n<pre>@PostMapping(\"/users\")<br>@ResponseStatus(HttpStatus.CREATED)<br>public UserDto signup(@RequestBody UserForm userForm){<br>    return userService.signup(userForm);<br>}</pre>\n<p>Now, say you have another handler for updating users, looking like\u00a0this:</p>\n<pre>@PutMapping(\"/users/{id}\")<br>public UserDto updateUser(@pathVariable long id, @RequestBody UserForm userForm) {<br><br>  return userService.update(id, userForm);<br>}</pre>\n<p>Notice the same userForm<strong>\u00a0</strong>above?</p>\n<p>Consequently, someone can call the endpoint with the unrequired fields (e.g., username and password), thus injecting those into your\u00a0form.</p>\n<p>This is where the @JsonView annotation could be really useful. You can define @JsonView on fields that need to be included in the API response.</p>\n<p>But the question is: Gow do we inform the Jackson processor to consider only certain fields based on the\u00a0API?</p>\n<h3>How to Use @JsonView</h3>\n<p>We can use @JsonView to limit or control-field display for different users. You can decide which properties to be serialized based on the View class provided in the JsonView annotation. Sounds interesting, right?</p>\n<p>To prevent the kind of injection discussed above, first define a marker interface, as\u00a0below:</p>\n<pre>public interface UpdateUser {}</pre>\n<p>Then, in userForm<strong>, </strong>annotate the fields you want to receive when updating with @JsonView(UpdateUser.class):</p>\n<pre>public class UserForm {<br><br>  private String username;<br><br>  @JsonView(UpdateUser.class)<br>  private String name;<br><br>  private String password;<br><br>  // Getters and Setters ...<br>}</pre>\n<p>Now our model is ready, but this isn\u2019t enough. We should make sure our REST API methods are annotated with @JsonView, as shown below. So finally, use the same annotation in the handler, as\u00a0below:</p>\n<pre>@PutMapping(\"/users/{id}\")<br>public UserDto updateUser(@pathVariable long id,<br>  @RequestBody @JsonView(UpdateUser.class) UserForm userForm) {<br><br>   return userService.update(id, userForm);<br>}</pre>\n<p>That\u2019s all you need to prevent the injection.</p>\n<h3>Conclusion</h3>\n<p>This is very useful, particularly when you\u2019re reusing the domain classes as forms. For example, if you reuse a User domain class as the form and then save it straight to the database, you can get hacked, and this is where the real trouble comes\u00a0in.</p>\n<p>When registering, what if a malicious user adds an id or a createdDate field, that gets injected instead of autogenerated?</p>\n<p>Take a few minutes and ponder over the question before you jump to a conclusion.</p>\n<p>I hope you learned something from this article. Also please share if there are better alternatives. See you in another article\u00a0soon.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3b1230f1ae30\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://betterprogramming.pub/avoid-security-loopholes-using-jsonview-in-spring-boot-3b1230f1ae30\">Avoid Security Loopholes Using @JsonView in Spring Boot</a> was originally published in <a href=\"https://betterprogramming.pub/\">Better Programming</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n","enclosure":{},"categories":["spring-boot","programming","java","api","web-development"]},{"title":"The Guide To Core Redux Concepts","pubDate":"2020-10-03 00:00:00","link":"https://medium.com/@paruldhingra/the-guide-to-core-redux-concepts-d5f127d1604?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/d5f127d1604","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/617/1*R6rW5fCKVXWkD85tjkHBjw.png","description":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/617/1*R6rW5fCKVXWkD85tjkHBjw.png\"><figcaption>Photo from linguinecode.com</figcaption></figure><p>In a React app, data is fetched in the parent component and then passed down to child components through\u00a0props.</p>\n<p>Things get complicated when there are many layers of components and data/state (and the functions that modify this state) are passed through numerous components to get from origin to destination. This path can be <strong>difficult to remember</strong> and it leaves <strong>many places for errors to be introduced</strong>.</p>\n<blockquote><em>With Redux, any component can be connected directly to state.####</em></blockquote>\n<p>This isn\u2019t to say that data is no longer passed down from parent components to child components via props. Rather, this path can now be direct, no passing props down from parent to great-great-great-great-great-great-grandchild.</p>\n<p>It\u2019s not good practice to have <em>all</em> components connect to application state. It is best to have parent/container components connect to state and <strong>pass state directly to children</strong>.</p>\n<p>The underlying principles are so darn\u00a0easy!</p>\n<h3>What is\u00a0Redux?</h3>\n<p>It is basically your state management library, commonly paired with React, where it takes control of state away from React components and give it to a centralized place known as a\u00a0<strong>\u2018store\u2019.</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/576/1*tFbYKrJwLD-TEkRbJqrrmg.png\"></figure><p>This time, when a component initiates a change, that information goes straight from it (the blue circle) to our store. From there, the change is then communicated directly to all the components that need to\u00a0update.</p>\n<p>Before jumping into the code, it\u2019s useful to think about how Redux is working conceptually. The diagram below illustrates a typical Redux\u00a0flow.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/512/1*SvVHC0jaOjrj5USZgTUGeg.png\"></figure><p>1.<strong> Store</strong>: A Redux Store holds your application\u2019s state. It is where you will find three critical\u00a0methods:</p>\n<p>2. <strong>Actions: </strong>In Redux, actions provide information to the store. Although Redux is different from an MVC framework, I would say that an action is basically the equivalent of a model in MVC. It has two parameters:</p>\n<pre>const ADD_TODO =<br>{ type: \"ADD_TODO\",<br>  payload: \"Do stuff\" <br>}</pre>\n<p>The first is <em>type</em>, which must always be present. The <em>payload</em> key can really be anything that is descriptive of the data being passed. With this data in the action, reducers will do the job of modifying the application\u2019s state.</p>\n<p>3.<strong> Reducers</strong>: A reducer takes an action and based on action type. It will decide what needs to be done with the data (ie. how will it effect your application\u2019s state). Reducers are where application state gets\u00a0update.</p>\n<p>4. <strong>State: </strong>Finally, state is contained within the store. It is a concept you should be familiar with from React. In short, it is an object that represents the dynamic parts of the app: anything that may change on the client-side.</p>\n<h3>Now let\u2019s create a simple app with\u00a0Redux:</h3>\n<p>Hurray!</p>\n<p>If that didn\u2019t get you excited, I don\u2019t know what will. I\u2019m super excited for\u00a0it!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/250/1*mWFQlZQbqB9rjPaToV_M1w.gif\"></figure><p>We\u2019ll begin with a simple example. Ensure you have Node.js installed, then type the following into your terminal:</p>\n<h3>Step-1</h3>\n<p>Create a new react\u00a0app:</p>\n<pre>npx create-react-app addpost</pre>\n<h3>Step-2</h3>\n<p>Install dependencies:</p>\n<pre>npm install lodash @material-ui/core @material-ui/icons react-redux redux redux-logger</pre>\n<h3>Step-3</h3>\n<p>Create the necessary files and folders manually and make sure your folder structure is the same as\u00a0mine:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/270/1*9yZ58HPCiVMjgQdu9qOz1w.jpeg\"></figure><h3>Step-4</h3>\n<p>To set up our UI, create a file called src/components/posts.js and paste in the following code:</p>\n<pre>import <strong><em>React</em></strong>, { Component } from \"react\";<br>import {<br>    withStyles,<br><strong><em>List</em></strong>,<br><strong><em>ListItem</em></strong>,<br>    ListItemSecondaryAction,<br>    ListItemText,<br><strong><em>IconButton</em></strong>,<br><strong><em>Grid</em></strong>,<br>    TextField,<br><strong><em>Button</em></strong>,<br><strong><em>FormControl<br></em></strong>} from \"@material-ui/core\";<br>import <strong><em>DeleteIcon </em></strong>from \"@material-ui/icons/Delete\";<br><br>const styles = theme =&gt; ({<br>    root: {<br>        flexGrow: 1,<br>        maxWidth: 752<br>    },<br>    demo: {<br>        backgroundColor: theme.palette.background.paper<br>    },<br>    title: {<br>        margin: `${theme.spacing.<strong><em>unit </em></strong>* 4}px 0 ${theme.spacing.<strong><em>unit </em></strong>* 2}px`<br>    }<br>});<br><br>class posts extends Component {<br>    state = {};<br><br>    generate = () =&gt; {<br>        return this.props.items.map(item =&gt; (<br>            &lt;ListItem key={item.id}&gt;<br>                &lt;ListItemText primary={item.description} /&gt;<br>                &lt;ListItemSecondaryAction&gt;<br>                    &lt;IconButton<br>                        aria-label=\"Delete\"<br>                        onClick={this.handleDelete}<br>                        value={item.id}<br>                    &gt;<br>                        &lt;DeleteIcon /&gt;<br>                    &lt;/IconButton&gt;<br>                &lt;/ListItemSecondaryAction&gt;<br>            &lt;/ListItem&gt;<br>        ));<br>    };<br><br>    handleSubmit = event =&gt; {<br>        // console.log(this.state.post);<br>        this.setState({ post: \"\" });<br>        if (this.state.post !== \"\") {<br>            // add the post to store<br><br>        }<br>        event.preventDefault();<br>    };<br>    handleDelete = event =&gt; {<br>        //delete the task from the store<br><br>    };<br>    handleChange = event =&gt; {<br>        this.setState({<br>            [event.target.name]: event.target.value<br>        });<br>    };<br><br>    render() {<br>        const { classes } = this.props;<br><br>        return (<br>            &lt;div&gt;<br>                &lt;div&gt;<br>                    &lt;form noValidate autoComplete=\"off\" onSubmit={this.handleSubmit}&gt;<br>                        &lt;FormControl&gt;<br>                            &lt;TextField<br>                                label=\"New Post\"<br>                                id=\"margin-dense\"<br>                                value={this.state.post}<br>                                className={classes.textField}<br>                                margin=\"dense\"<br>                                name=\"post\"<br>                                onChange={this.handleChange}<br>                            /&gt;<br>                        &lt;/FormControl&gt;<br>                        &lt;FormControl&gt;<br>                            &lt;Button&gt;Add&lt;/Button&gt;<br>                        &lt;/FormControl&gt;<br>                    &lt;/form&gt;<br>                &lt;/div&gt;<br>                &lt;div&gt;<br>                    &lt;Grid item container justify=\"space-evenly\" alignItems=\"center\"&gt;<br>                        &lt;div className={classes.demo}&gt;<br>                            &lt;List dense={false}&gt;{this.generate()}&lt;/List&gt;<br>                        &lt;/div&gt;<br>                    &lt;/Grid&gt;<br>                &lt;/div&gt;<br>            &lt;/div&gt;<br>        );<br>    }<br>}<br><br>export default withStyles(styles)(posts);</pre>\n<h3>actions.js:</h3>\n<p>We\u2019ll start by defining our actions. An action can be an object or, simple\u00a0string.</p>\n<pre>//types of action<br>const Types = {<br>    CREATE_POST: \"CREATE_POST\",<br>    DELETE_POST: \"DELETE_POST\"<br>};<br>// actions<br>const createPost = task =&gt; ({<br>    type: Types.CREATE_POST,<br>    payload: task<br>});<br><br>const deletePost = id =&gt; ({<br>    type: Types.DELETE_POST,<br>    payload: id<br>});<br><br>export default {<br>    createPost,<br>    deletePost,<br>    Types<br>};</pre>\n<blockquote>Ideally, you should create another file for your action\u00a0types.</blockquote>\n<h3>reducer.js</h3>\n<p>Next, we need to specify how the application\u2019s state should change in response to each action. This takes two arguments:</p>\n<ul>\n<li>a state;</li>\n<li>an action, which defines how we go about changing\u00a0state.</li>\n</ul>\n<pre>import ACTIONS from \"./action\";<br>import _from \"lodash\";<br><br>const defaultState = {<br>    items: []<br>};<br><br>const postReducer = (state = defaultState, action) =&gt; {<br>    switch (action.type) {<br>        case ACTIONS.Types.CREATE_POST: {<br><strong><em>console</em></strong>.log(action);<br><br>            let post = action.payload;<br>            let newPost = { id: state.items.length + 1, description: post };<br>            let newState = (state);<br>            newState.items.push(newPost);<br>            return newState;<br>        }<br><br>        case ACTIONS.Types.DELETE_POST: {<br>            let newState = _.clonedeep(state);<br>            let index = _.findIndex(newState.items, {id: action.payload});<br>            newState.items.splice(index, 1);<br>            return newState;<br>        }<br><br>        default:<br>            return state;<br>    }<br>};<br><br>export default postReducer;</pre>\n<p>Note that it\u2019s common to use switch statements to distinguish action types here, but regular if and else statements will work fine\u00a0too.</p>\n<h3>store.js</h3>\n<p>When all that\u2019s done, we\u2019ll need to import the createStore function from \u2018redux\u2019 and pass in our reducer, like\u00a0so:</p>\n<pre>import { <strong><em>createStore</em></strong>, applyMiddleware } from \"redux\";<br><br>//Logger with default options<br>import Logger from \"redux-logger\";<br>import reducer from \"./reducer\";<br><br>export default function configureStore(initialState) {<br>    const store = <strong><em>createStore</em></strong>(reducer, initialState, applyMiddleware());<br>    return store;<br>}</pre>\n<h3>App.js</h3>\n<p>Now that we\u2019ve exported our store we need to import it into App.js\u00a0, by passing it into React-Redux\u2019s Provider component:</p>\n<pre>import <strong><em>React</em></strong>, { Component } from \"react\";<br>import <strong><em>logo </em></strong>from \"./logo.svg\";<br>import \"./App.css\";<br>import ToDO from \"./components/posts\";<br>import { Provider as ReduxProvider } from \"react-redux\";<br>import configureStore from \"./modules/store\";<br><br>const reduxStore = configureStore(<strong><em>window</em></strong>.REDUX_INITIAL_DATA);<br><br>class App extends Component {<br>  render() {<br>    return (<br>        &lt;ReduxProvider store={reduxStore}&gt;<br>          &lt;div className=\"App\"&gt;<br>            &lt;header className=\"App-header\"&gt;<br>                &lt;img src={<strong><em>logo</em></strong>} className=\"App-logo\" alt={\"logo\"}/&gt;<br>                &lt;h1 className=\"App-title\"&gt;Create Post&lt;/h1&gt;<br>            &lt;/header&gt;<br>            &lt;Post /&gt;<br>          &lt;/div&gt;<br>        &lt;/ReduxProvider&gt;<br>    );<br>  }<br>}<br><br>export default App;</pre>\n<p>This means that any child of the Provider component can access our store and, therefore, our actions and reducers.</p>\n<p>Finally, we need to connect our component to our store, which we can do by importing connect (which is a higher order function) from the react-redux module:</p>\n<pre>import {connect} from 'react-redux';</pre>\n<p>The connect function must be used to export any component that needs to access to change Redux\u00a0state.</p>\n<h3>Adding Redux\u00a0DevTools</h3>\n<p>A final useful step to working with Redux is to install and initiate Redux\u2019s own development tools.</p>\n<p>If you\u2019re using Chrome, you can enable Redux DevTools by following the link\u00a0below:</p>\n<p><a href=\"https://chrome.google.com/webstore/detail/redux-devtools/lmhkpmbekcpmknklioeibfkpmmfibljd?hl=en&amp;ref=hackernoon.com\">https://chrome.google.com/webstore/detail/redux-devtools/lmhkpmbekcpmknklioeibfkpmmfibljd?hl=en</a></p>\n<h3>Wrapping up</h3>\n<p>What a journey! I hope you learned something from this guide. Tried my best to keep things as simple as possible. Pick Redux, play with it and take your time to absorb all the concepts.</p>\n<p>Thanks for reading and happy coding!\u00a0:)</p>\n<p><em>Originally published at </em><a href=\"https://hackernoon.com/the-guide-to-core-redux-concepts-ncu3tcw\"><em>https://hackernoon.com</em></a><em> on October 3,\u00a02020.</em></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d5f127d1604\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/617/1*R6rW5fCKVXWkD85tjkHBjw.png\"><figcaption>Photo from linguinecode.com</figcaption></figure><p>In a React app, data is fetched in the parent component and then passed down to child components through\u00a0props.</p>\n<p>Things get complicated when there are many layers of components and data/state (and the functions that modify this state) are passed through numerous components to get from origin to destination. This path can be <strong>difficult to remember</strong> and it leaves <strong>many places for errors to be introduced</strong>.</p>\n<blockquote><em>With Redux, any component can be connected directly to state.####</em></blockquote>\n<p>This isn\u2019t to say that data is no longer passed down from parent components to child components via props. Rather, this path can now be direct, no passing props down from parent to great-great-great-great-great-great-grandchild.</p>\n<p>It\u2019s not good practice to have <em>all</em> components connect to application state. It is best to have parent/container components connect to state and <strong>pass state directly to children</strong>.</p>\n<p>The underlying principles are so darn\u00a0easy!</p>\n<h3>What is\u00a0Redux?</h3>\n<p>It is basically your state management library, commonly paired with React, where it takes control of state away from React components and give it to a centralized place known as a\u00a0<strong>\u2018store\u2019.</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/576/1*tFbYKrJwLD-TEkRbJqrrmg.png\"></figure><p>This time, when a component initiates a change, that information goes straight from it (the blue circle) to our store. From there, the change is then communicated directly to all the components that need to\u00a0update.</p>\n<p>Before jumping into the code, it\u2019s useful to think about how Redux is working conceptually. The diagram below illustrates a typical Redux\u00a0flow.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/512/1*SvVHC0jaOjrj5USZgTUGeg.png\"></figure><p>1.<strong> Store</strong>: A Redux Store holds your application\u2019s state. It is where you will find three critical\u00a0methods:</p>\n<p>2. <strong>Actions: </strong>In Redux, actions provide information to the store. Although Redux is different from an MVC framework, I would say that an action is basically the equivalent of a model in MVC. It has two parameters:</p>\n<pre>const ADD_TODO =<br>{ type: \"ADD_TODO\",<br>  payload: \"Do stuff\" <br>}</pre>\n<p>The first is <em>type</em>, which must always be present. The <em>payload</em> key can really be anything that is descriptive of the data being passed. With this data in the action, reducers will do the job of modifying the application\u2019s state.</p>\n<p>3.<strong> Reducers</strong>: A reducer takes an action and based on action type. It will decide what needs to be done with the data (ie. how will it effect your application\u2019s state). Reducers are where application state gets\u00a0update.</p>\n<p>4. <strong>State: </strong>Finally, state is contained within the store. It is a concept you should be familiar with from React. In short, it is an object that represents the dynamic parts of the app: anything that may change on the client-side.</p>\n<h3>Now let\u2019s create a simple app with\u00a0Redux:</h3>\n<p>Hurray!</p>\n<p>If that didn\u2019t get you excited, I don\u2019t know what will. I\u2019m super excited for\u00a0it!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/250/1*mWFQlZQbqB9rjPaToV_M1w.gif\"></figure><p>We\u2019ll begin with a simple example. Ensure you have Node.js installed, then type the following into your terminal:</p>\n<h3>Step-1</h3>\n<p>Create a new react\u00a0app:</p>\n<pre>npx create-react-app addpost</pre>\n<h3>Step-2</h3>\n<p>Install dependencies:</p>\n<pre>npm install lodash @material-ui/core @material-ui/icons react-redux redux redux-logger</pre>\n<h3>Step-3</h3>\n<p>Create the necessary files and folders manually and make sure your folder structure is the same as\u00a0mine:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/270/1*9yZ58HPCiVMjgQdu9qOz1w.jpeg\"></figure><h3>Step-4</h3>\n<p>To set up our UI, create a file called src/components/posts.js and paste in the following code:</p>\n<pre>import <strong><em>React</em></strong>, { Component } from \"react\";<br>import {<br>    withStyles,<br><strong><em>List</em></strong>,<br><strong><em>ListItem</em></strong>,<br>    ListItemSecondaryAction,<br>    ListItemText,<br><strong><em>IconButton</em></strong>,<br><strong><em>Grid</em></strong>,<br>    TextField,<br><strong><em>Button</em></strong>,<br><strong><em>FormControl<br></em></strong>} from \"@material-ui/core\";<br>import <strong><em>DeleteIcon </em></strong>from \"@material-ui/icons/Delete\";<br><br>const styles = theme =&gt; ({<br>    root: {<br>        flexGrow: 1,<br>        maxWidth: 752<br>    },<br>    demo: {<br>        backgroundColor: theme.palette.background.paper<br>    },<br>    title: {<br>        margin: `${theme.spacing.<strong><em>unit </em></strong>* 4}px 0 ${theme.spacing.<strong><em>unit </em></strong>* 2}px`<br>    }<br>});<br><br>class posts extends Component {<br>    state = {};<br><br>    generate = () =&gt; {<br>        return this.props.items.map(item =&gt; (<br>            &lt;ListItem key={item.id}&gt;<br>                &lt;ListItemText primary={item.description} /&gt;<br>                &lt;ListItemSecondaryAction&gt;<br>                    &lt;IconButton<br>                        aria-label=\"Delete\"<br>                        onClick={this.handleDelete}<br>                        value={item.id}<br>                    &gt;<br>                        &lt;DeleteIcon /&gt;<br>                    &lt;/IconButton&gt;<br>                &lt;/ListItemSecondaryAction&gt;<br>            &lt;/ListItem&gt;<br>        ));<br>    };<br><br>    handleSubmit = event =&gt; {<br>        // console.log(this.state.post);<br>        this.setState({ post: \"\" });<br>        if (this.state.post !== \"\") {<br>            // add the post to store<br><br>        }<br>        event.preventDefault();<br>    };<br>    handleDelete = event =&gt; {<br>        //delete the task from the store<br><br>    };<br>    handleChange = event =&gt; {<br>        this.setState({<br>            [event.target.name]: event.target.value<br>        });<br>    };<br><br>    render() {<br>        const { classes } = this.props;<br><br>        return (<br>            &lt;div&gt;<br>                &lt;div&gt;<br>                    &lt;form noValidate autoComplete=\"off\" onSubmit={this.handleSubmit}&gt;<br>                        &lt;FormControl&gt;<br>                            &lt;TextField<br>                                label=\"New Post\"<br>                                id=\"margin-dense\"<br>                                value={this.state.post}<br>                                className={classes.textField}<br>                                margin=\"dense\"<br>                                name=\"post\"<br>                                onChange={this.handleChange}<br>                            /&gt;<br>                        &lt;/FormControl&gt;<br>                        &lt;FormControl&gt;<br>                            &lt;Button&gt;Add&lt;/Button&gt;<br>                        &lt;/FormControl&gt;<br>                    &lt;/form&gt;<br>                &lt;/div&gt;<br>                &lt;div&gt;<br>                    &lt;Grid item container justify=\"space-evenly\" alignItems=\"center\"&gt;<br>                        &lt;div className={classes.demo}&gt;<br>                            &lt;List dense={false}&gt;{this.generate()}&lt;/List&gt;<br>                        &lt;/div&gt;<br>                    &lt;/Grid&gt;<br>                &lt;/div&gt;<br>            &lt;/div&gt;<br>        );<br>    }<br>}<br><br>export default withStyles(styles)(posts);</pre>\n<h3>actions.js:</h3>\n<p>We\u2019ll start by defining our actions. An action can be an object or, simple\u00a0string.</p>\n<pre>//types of action<br>const Types = {<br>    CREATE_POST: \"CREATE_POST\",<br>    DELETE_POST: \"DELETE_POST\"<br>};<br>// actions<br>const createPost = task =&gt; ({<br>    type: Types.CREATE_POST,<br>    payload: task<br>});<br><br>const deletePost = id =&gt; ({<br>    type: Types.DELETE_POST,<br>    payload: id<br>});<br><br>export default {<br>    createPost,<br>    deletePost,<br>    Types<br>};</pre>\n<blockquote>Ideally, you should create another file for your action\u00a0types.</blockquote>\n<h3>reducer.js</h3>\n<p>Next, we need to specify how the application\u2019s state should change in response to each action. This takes two arguments:</p>\n<ul>\n<li>a state;</li>\n<li>an action, which defines how we go about changing\u00a0state.</li>\n</ul>\n<pre>import ACTIONS from \"./action\";<br>import _from \"lodash\";<br><br>const defaultState = {<br>    items: []<br>};<br><br>const postReducer = (state = defaultState, action) =&gt; {<br>    switch (action.type) {<br>        case ACTIONS.Types.CREATE_POST: {<br><strong><em>console</em></strong>.log(action);<br><br>            let post = action.payload;<br>            let newPost = { id: state.items.length + 1, description: post };<br>            let newState = (state);<br>            newState.items.push(newPost);<br>            return newState;<br>        }<br><br>        case ACTIONS.Types.DELETE_POST: {<br>            let newState = _.clonedeep(state);<br>            let index = _.findIndex(newState.items, {id: action.payload});<br>            newState.items.splice(index, 1);<br>            return newState;<br>        }<br><br>        default:<br>            return state;<br>    }<br>};<br><br>export default postReducer;</pre>\n<p>Note that it\u2019s common to use switch statements to distinguish action types here, but regular if and else statements will work fine\u00a0too.</p>\n<h3>store.js</h3>\n<p>When all that\u2019s done, we\u2019ll need to import the createStore function from \u2018redux\u2019 and pass in our reducer, like\u00a0so:</p>\n<pre>import { <strong><em>createStore</em></strong>, applyMiddleware } from \"redux\";<br><br>//Logger with default options<br>import Logger from \"redux-logger\";<br>import reducer from \"./reducer\";<br><br>export default function configureStore(initialState) {<br>    const store = <strong><em>createStore</em></strong>(reducer, initialState, applyMiddleware());<br>    return store;<br>}</pre>\n<h3>App.js</h3>\n<p>Now that we\u2019ve exported our store we need to import it into App.js\u00a0, by passing it into React-Redux\u2019s Provider component:</p>\n<pre>import <strong><em>React</em></strong>, { Component } from \"react\";<br>import <strong><em>logo </em></strong>from \"./logo.svg\";<br>import \"./App.css\";<br>import ToDO from \"./components/posts\";<br>import { Provider as ReduxProvider } from \"react-redux\";<br>import configureStore from \"./modules/store\";<br><br>const reduxStore = configureStore(<strong><em>window</em></strong>.REDUX_INITIAL_DATA);<br><br>class App extends Component {<br>  render() {<br>    return (<br>        &lt;ReduxProvider store={reduxStore}&gt;<br>          &lt;div className=\"App\"&gt;<br>            &lt;header className=\"App-header\"&gt;<br>                &lt;img src={<strong><em>logo</em></strong>} className=\"App-logo\" alt={\"logo\"}/&gt;<br>                &lt;h1 className=\"App-title\"&gt;Create Post&lt;/h1&gt;<br>            &lt;/header&gt;<br>            &lt;Post /&gt;<br>          &lt;/div&gt;<br>        &lt;/ReduxProvider&gt;<br>    );<br>  }<br>}<br><br>export default App;</pre>\n<p>This means that any child of the Provider component can access our store and, therefore, our actions and reducers.</p>\n<p>Finally, we need to connect our component to our store, which we can do by importing connect (which is a higher order function) from the react-redux module:</p>\n<pre>import {connect} from 'react-redux';</pre>\n<p>The connect function must be used to export any component that needs to access to change Redux\u00a0state.</p>\n<h3>Adding Redux\u00a0DevTools</h3>\n<p>A final useful step to working with Redux is to install and initiate Redux\u2019s own development tools.</p>\n<p>If you\u2019re using Chrome, you can enable Redux DevTools by following the link\u00a0below:</p>\n<p><a href=\"https://chrome.google.com/webstore/detail/redux-devtools/lmhkpmbekcpmknklioeibfkpmmfibljd?hl=en&amp;ref=hackernoon.com\">https://chrome.google.com/webstore/detail/redux-devtools/lmhkpmbekcpmknklioeibfkpmmfibljd?hl=en</a></p>\n<h3>Wrapping up</h3>\n<p>What a journey! I hope you learned something from this guide. Tried my best to keep things as simple as possible. Pick Redux, play with it and take your time to absorb all the concepts.</p>\n<p>Thanks for reading and happy coding!\u00a0:)</p>\n<p><em>Originally published at </em><a href=\"https://hackernoon.com/the-guide-to-core-redux-concepts-ncu3tcw\"><em>https://hackernoon.com</em></a><em> on October 3,\u00a02020.</em></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d5f127d1604\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["web-development","front-end-development","react","redux","javascript"]},{"title":"Quick Tips to Use Postman Smartly","pubDate":"2020-09-18 22:26:06","link":"https://betterprogramming.pub/quick-tips-to-use-postman-smartly-a95ca1bc67cf?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/a95ca1bc67cf","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/600/1*K9F7J4l6kAVy5W8Gc3kA5Q.png","description":"<div class=\"medium-feed-item\">\n<p class=\"medium-feed-image\"><a href=\"https://betterprogramming.pub/quick-tips-to-use-postman-smartly-a95ca1bc67cf?source=rss-6e9b39ccfd81------2\"><img src=\"https://cdn-images-1.medium.com/max/600/1*K9F7J4l6kAVy5W8Gc3kA5Q.png\" width=\"600\"></a></p>\n<p class=\"medium-feed-snippet\">How to get the most out of Postman in your development</p>\n<p class=\"medium-feed-link\"><a href=\"https://betterprogramming.pub/quick-tips-to-use-postman-smartly-a95ca1bc67cf?source=rss-6e9b39ccfd81------2\">Continue reading on Better Programming \u00bb</a></p>\n</div>","content":"<div class=\"medium-feed-item\">\n<p class=\"medium-feed-image\"><a href=\"https://betterprogramming.pub/quick-tips-to-use-postman-smartly-a95ca1bc67cf?source=rss-6e9b39ccfd81------2\"><img src=\"https://cdn-images-1.medium.com/max/600/1*K9F7J4l6kAVy5W8Gc3kA5Q.png\" width=\"600\"></a></p>\n<p class=\"medium-feed-snippet\">How to get the most out of Postman in your development</p>\n<p class=\"medium-feed-link\"><a href=\"https://betterprogramming.pub/quick-tips-to-use-postman-smartly-a95ca1bc67cf?source=rss-6e9b39ccfd81------2\">Continue reading on Better Programming \u00bb</a></p>\n</div>","enclosure":{},"categories":["programming","api","software-development","postman","web-development"]},{"title":"Decrease CPU power consumption while it is operating","pubDate":"2020-08-23 07:40:42","link":"https://medium.com/@paruldhingra/decrease-cpu-power-consumption-while-it-is-operating-d705838664f5?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/d705838664f5","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/1024/1*ay7gyZX0p2gSdAfef_cl-A.png","description":"\n<p>If your application is experiencing terrible latencies and delivering a frustrating user experience, you may target high CPU loads as the main problem to\u00a0solve.</p>\n<p>The processor/CPU is designed to operate forever under a specific load. As almost none of us are doing a 24x7 calculation employing all the resources of the CPU continuously, it is most of the time not operating in its designed maximum. So what is the point of keeping the whole CPU powered on at its full capacity\u00a0?</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ay7gyZX0p2gSdAfef_cl-A.png\"></figure><p>This is the point of CPU power management. The power management topic covers much more than this, including the RAM, GPU etc., but I am going to tell you only about the CPU side of the story in this\u00a0post.</p>\n<p>On a production CPU (so not considering the things that can be done while designing the CPU), to save power, you can do two things. You\u00a0can:</p>\n<ul>\n<li>\n<strong>Powering down subsystems</strong>\u00a0: eliminate the power consumption of a subsystem (a core or other resources like clock or cache) by completely powering it down (so cutting down the voltage, reducing it to zero)\u00a0or,</li>\n<li>\n<strong>Voltage/frequency reduction</strong>\u00a0: decrease the power consumption by decreasing the voltage and/or the frequency of the subsystem and/or the whole processor as power consumption is proportional linearly to frequency and quadratically to voltage i.e., P ~ f\u00a0V\u00b2.</li>\n</ul>\n<p>The first one is simple to understand, if you shut down the power, you do not consume any\u00a0power.</p>\n<p>The second requires a bit more explanation. It\u2019s is accomplished by\u00a0using:</p>\n<ul>\n<li>C-states</li>\n<li>P-states</li>\n</ul>\n<p>Power management happens both when the processor is idle and otherwise.</p>\n<p>Idle states of a processor are called <strong>C-states\u00a0. </strong>They are<strong> </strong>ideal (power saving) states and are denoted as C0, C1,\u00a0C2\u2026</p>\n<p>C0 is the operating state whereas C1, C2, C3.. are states where some or more of the subsystems are shutdown. Generally the higher the C-state the lower the power consumption but also the longer it takes for the processor to move back to the operating state\u00a0C0.</p>\n<p>Many modern CPUs have plenty more C-states.</p>\n<p>We can look at the idle states available on my laptop using the cpupower\u00a0command:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ifi7OF5YBhn26SMXptTvxw.png\"></figure><p>We can see that my processor has these idle states available: POLL, C1, C1E, C3, C6, C7s, C8, C9, C10. We can also see a Latency field that tells us the maximum time (in \u00b5s) the processor will take to go from that state to the operating C0 state. It is possible to enable/disable these states using the cpupower idle-set command.`</p>\n<p>Similarly when a processor is not idle it will be in one of several <strong>P-states </strong>i.e.,<strong> </strong>executing (power saving) states denoted by P0, P1, P2,\u00a0P3.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*m7Km_8Q1HpsFT7ww02gKyg.png\"></figure><p>That means, the subsystem is actually running but it does not require full performance so the voltage and/or frequency it operates is decreased. So P-state Px, means the subsystem it refers to (e.g. a CPU core) is operating at a specific (frequency, voltage)\u00a0pair.</p>\n<p>The <em>higher</em> the p-state, the <em>lower</em> the voltage and operating frequency of the processor. This means CPU bound programs will in general execute faster in a lower P-state than a higher\u00a0p-state.</p>\n<blockquote>The states are numbered starting from zero like C0, C1\u2026 and P0, P1\u2026 The higher the number is the more power is saved. C0 means no power saving by shutting down something, so everything is powered on. P0 means maximum performance, thus maximum frequency, voltage and power\u00a0used.</blockquote>\n<p>We cannot explicitly set the processor to a particular state. However we can set a CPU Freq governor using the cpupower frequency-set -g &lt;governor&gt; command.</p>\n<p>You can think of the governors as a sort of pre-configured power scheme for the CPU. The CPU freq governors use P-states to change frequencies and lower power consumption. The dynamic governors can switch between CPU frequencies, based on CPU usage, to allow for power savings while not sacrificing performance.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/707/1*VuP1WWfmJU_wBNNtKh07vw.png\"><figcaption>CPU with max request in freq domain drives frequency</figcaption></figure><h3>How does governors improve the situation?</h3>\n<p>There are several governors available with the CPUfreq subsystem. Some of it\u00a0are:</p>\n<p><strong>Performance Governor\u00a0: </strong>The CPU frequency is statically set to the highest possible for maximum performance. It basically reduces latency as the CPU is more ready to ramp up and do work when it comes. Consequently, saving power is not the focus of this governor.</p>\n<p><strong>Powersave Governor\u00a0: </strong>The CPU frequency is statically set to the lowest possible. This can have severe impact on the performance, as the system will never rise above this frequency no matter how busy the processors are.</p>\n<p>Thus, using powersave governor and by achieving ideal states through entering C-states, you can achieve much power savings because processes run at the lowest/minimum frequency with this though, it may take longer to finish. On the contrary, disabling idle states i.e., CPU is running at peak frequency continuously and using the performance governor has the effect of consuming more power, though it improves the average latency as the CPU is more ready to ramp up and do work when it\u00a0comes.</p>\n<p>And that\u2019s a\u00a0wrap!</p>\n<p>Thanks so much for reading. Have a wonderful week!</p>\n<p>Do share your feedback and suggestions in the comments section\u00a0below.</p>\n<h3>If you liked this blog, hit the \ud83d\udc4f\u00a0. Stay\u00a0tuned.</h3>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d705838664f5\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>If your application is experiencing terrible latencies and delivering a frustrating user experience, you may target high CPU loads as the main problem to\u00a0solve.</p>\n<p>The processor/CPU is designed to operate forever under a specific load. As almost none of us are doing a 24x7 calculation employing all the resources of the CPU continuously, it is most of the time not operating in its designed maximum. So what is the point of keeping the whole CPU powered on at its full capacity\u00a0?</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ay7gyZX0p2gSdAfef_cl-A.png\"></figure><p>This is the point of CPU power management. The power management topic covers much more than this, including the RAM, GPU etc., but I am going to tell you only about the CPU side of the story in this\u00a0post.</p>\n<p>On a production CPU (so not considering the things that can be done while designing the CPU), to save power, you can do two things. You\u00a0can:</p>\n<ul>\n<li>\n<strong>Powering down subsystems</strong>\u00a0: eliminate the power consumption of a subsystem (a core or other resources like clock or cache) by completely powering it down (so cutting down the voltage, reducing it to zero)\u00a0or,</li>\n<li>\n<strong>Voltage/frequency reduction</strong>\u00a0: decrease the power consumption by decreasing the voltage and/or the frequency of the subsystem and/or the whole processor as power consumption is proportional linearly to frequency and quadratically to voltage i.e., P ~ f\u00a0V\u00b2.</li>\n</ul>\n<p>The first one is simple to understand, if you shut down the power, you do not consume any\u00a0power.</p>\n<p>The second requires a bit more explanation. It\u2019s is accomplished by\u00a0using:</p>\n<ul>\n<li>C-states</li>\n<li>P-states</li>\n</ul>\n<p>Power management happens both when the processor is idle and otherwise.</p>\n<p>Idle states of a processor are called <strong>C-states\u00a0. </strong>They are<strong> </strong>ideal (power saving) states and are denoted as C0, C1,\u00a0C2\u2026</p>\n<p>C0 is the operating state whereas C1, C2, C3.. are states where some or more of the subsystems are shutdown. Generally the higher the C-state the lower the power consumption but also the longer it takes for the processor to move back to the operating state\u00a0C0.</p>\n<p>Many modern CPUs have plenty more C-states.</p>\n<p>We can look at the idle states available on my laptop using the cpupower\u00a0command:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ifi7OF5YBhn26SMXptTvxw.png\"></figure><p>We can see that my processor has these idle states available: POLL, C1, C1E, C3, C6, C7s, C8, C9, C10. We can also see a Latency field that tells us the maximum time (in \u00b5s) the processor will take to go from that state to the operating C0 state. It is possible to enable/disable these states using the cpupower idle-set command.`</p>\n<p>Similarly when a processor is not idle it will be in one of several <strong>P-states </strong>i.e.,<strong> </strong>executing (power saving) states denoted by P0, P1, P2,\u00a0P3.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*m7Km_8Q1HpsFT7ww02gKyg.png\"></figure><p>That means, the subsystem is actually running but it does not require full performance so the voltage and/or frequency it operates is decreased. So P-state Px, means the subsystem it refers to (e.g. a CPU core) is operating at a specific (frequency, voltage)\u00a0pair.</p>\n<p>The <em>higher</em> the p-state, the <em>lower</em> the voltage and operating frequency of the processor. This means CPU bound programs will in general execute faster in a lower P-state than a higher\u00a0p-state.</p>\n<blockquote>The states are numbered starting from zero like C0, C1\u2026 and P0, P1\u2026 The higher the number is the more power is saved. C0 means no power saving by shutting down something, so everything is powered on. P0 means maximum performance, thus maximum frequency, voltage and power\u00a0used.</blockquote>\n<p>We cannot explicitly set the processor to a particular state. However we can set a CPU Freq governor using the cpupower frequency-set -g &lt;governor&gt; command.</p>\n<p>You can think of the governors as a sort of pre-configured power scheme for the CPU. The CPU freq governors use P-states to change frequencies and lower power consumption. The dynamic governors can switch between CPU frequencies, based on CPU usage, to allow for power savings while not sacrificing performance.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/707/1*VuP1WWfmJU_wBNNtKh07vw.png\"><figcaption>CPU with max request in freq domain drives frequency</figcaption></figure><h3>How does governors improve the situation?</h3>\n<p>There are several governors available with the CPUfreq subsystem. Some of it\u00a0are:</p>\n<p><strong>Performance Governor\u00a0: </strong>The CPU frequency is statically set to the highest possible for maximum performance. It basically reduces latency as the CPU is more ready to ramp up and do work when it comes. Consequently, saving power is not the focus of this governor.</p>\n<p><strong>Powersave Governor\u00a0: </strong>The CPU frequency is statically set to the lowest possible. This can have severe impact on the performance, as the system will never rise above this frequency no matter how busy the processors are.</p>\n<p>Thus, using powersave governor and by achieving ideal states through entering C-states, you can achieve much power savings because processes run at the lowest/minimum frequency with this though, it may take longer to finish. On the contrary, disabling idle states i.e., CPU is running at peak frequency continuously and using the performance governor has the effect of consuming more power, though it improves the average latency as the CPU is more ready to ramp up and do work when it\u00a0comes.</p>\n<p>And that\u2019s a\u00a0wrap!</p>\n<p>Thanks so much for reading. Have a wonderful week!</p>\n<p>Do share your feedback and suggestions in the comments section\u00a0below.</p>\n<h3>If you liked this blog, hit the \ud83d\udc4f\u00a0. Stay\u00a0tuned.</h3>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d705838664f5\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["computer-science","operating-systems","linux","power-management","technology"]},{"title":"How to Limit and Manage the CPU Usage?","pubDate":"2020-07-24 09:19:40","link":"https://medium.com/@paruldhingra/how-to-limit-and-manage-the-cpu-usage-e9159cd2aa9b?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/e9159cd2aa9b","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/483/1*OSfcIzl1U0ZgLkyHYMjEZw.png","description":"\n<blockquote><em>The symptoms of high CPU usage are familiar: the cursor moves jerkily and slowly, and applications begin to lag or shut down. The workstation might even begin to physically heat up as it strains to perform tasks. When diagnosing a malfunctioning system, these are signs you should start by checking the processor.</em></blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/483/1*OSfcIzl1U0ZgLkyHYMjEZw.png\"></figure><p>At the core of any computing device is the Central Processing Unit (CPU), or processor, which is responsible for fulfilling the user\u2019s instructions. A device\u2019s CPU only has the capacity to deal with so many processes or tasks at once, and when those resources are strained, the computer\u2019s performance begins to\u00a0suffer.</p>\n<p>Most processes are started at the same priority level and the Linux kernel schedules time for each task evenly on the processor. Have a CPU intensive process that can be run at a lower priority? Then you need to tell the scheduler about\u00a0it!</p>\n<p>There are at least three ways in which you can control how much CPU time a process\u00a0gets:</p>\n<p>Use the <strong>nice </strong>command to manually lower the task\u2019s priority.</p>\n<p>A thread\u2019s weight is essentially its priority, or niceness in UNIX parlance. Threads with lower niceness have higher weights and vice\u00a0versa.</p>\n<p>The nice command tweaks the priority level of a process so that it runs less frequently. <strong>This is useful when you need to run a CPU intensive task as a background or batch job</strong>. The niceness level ranges from -20 (most favorable scheduling) to 19 (least favorable). Processes on Linux are started with a niceness of 0 by default. The nice command (without any additional parameters) will start a process with a niceness of 10. At that level the scheduler will see it as a lower priority task and give it less CPU resources.</p>\n<p>Use the <strong>cpulimit</strong> command to repeatedly pause the process so that it doesn't exceed a certain\u00a0limit.</p>\n<p>cpulimit<strong> is useful when you want to ensure that a process doesn't use more than a certain portion of the CPU.</strong> The disadvantage over nice is that the process can't use all of the available CPU time when the system is idle. It does not change the nice value of the process, instead it monitors and controls the real-world CPU\u00a0usage.</p>\n<p>Use Linux\u2019s built-in <strong>control groups</strong>, a mechanism which tells the scheduler to limit the amount of resources available to the\u00a0process.</p>\n<p>Control groups (cgroups) are a Linux kernel feature that allows you to specify how the kernel should allocate specific resources to a group of processes. With cgroups you can specify how much CPU time, system memory, network bandwidth, or combinations of these resources can be used by the processes residing in a certain\u00a0group.</p>\n<p><strong>The advantage of control groups over </strong>nice<strong> or </strong>cpulimit<strong> is that the limits are applied to a set of processes, rather than to just one.</strong> Also, nice or cpulimit only limit the CPU usage of a process, whereas cgroups can limit other process resources.</p>\n<p>By judiciously using cgroups the resources of entire subsystems of a server can be controlled. For example in CoreOS, the minimal Linux distribution designed for massive server deployments, the upgrade processes are controlled by a cgroup. This means the downloading and installing of system updates doesn\u2019t affect system performance.</p>\n<p>Linux uses a<strong> <em>Completely Fair Scheduling</em> </strong>(CFS) algorithm, which is an implementation of <em>weighted fair queueing</em>\u00a0(WFQ).</p>\n<p>Scheduling goal is to maximize power efficiency with only a modest performance sacrifice. the scheduler decides when one process ceases<br>running and the other\u00a0begins.</p>\n<p>When an interrupt happens, scheduler has to decide whether to grant CPU to some other process and, if so, to which one. The amount of time a process gets to run is called timeslice of a\u00a0process</p>\n<h3>What process should the scheduler pick\u00a0next?</h3>\n<p>The scheduler should maximize CPU utilization.</p>\n<p>Imagine a single CPU system to start with: CFS time-slices the CPU among running threads. There is a fixed time interval during which each thread in the system must run at least once. This interval is divided into <em>timeslices</em> that are allocated to threads according to their\u00a0weights.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/495/1*G9FH4eVULC7sZeaK-3Cn8Q.png\"></figure><p>A running thread accumulates <strong><em>vruntime</em> </strong>(runtime / weight). When a thread\u2019s vruntime exceeds its assigned timeslice it will be pre-empted.</p>\n<blockquote>\n<em>Threads are organized in a runqueue, implemented as a</em><strong><em> red-black tree</em></strong><em>, in which the threads are sorted in the increasing order of their vruntime. When a CPU looks for a new thread to run it picks the leftmost node in the red-black tree, which contains the thread with the smallest vruntime.</em>\n</blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/593/1*JgkihpQPz3H63zT4OP2ehw.png\"></figure><p>So far so good, but now we have to talk about multi-core systems\u2026</p>\n<p>Firstly we need per-core runqueues so that context switches can be fast. Now we have a new problem of balancing work across multiple runqueues.</p>\n<blockquote>\n<em>Consider a dual-core system with two runqueues that are not balanced. Suppose that one queue has one low-priority thread and another has ten high-priority threads. If each core looked for work only in its local runqueue, then high-priority threads would get a lot less CPU time than the low-priority thread, which is not what we want. We could have each core checknot only its runqueue but also the queues of other cores,but this would defeat the purpose of per-core runqueues. Therefore, what Linux and most other schedulers do is periodically run a </em><strong><em>load-balancing algorithm</em></strong><em> that will keep the queues roughly balanced.</em>\n</blockquote>\n<h3>How Load balancing works?</h3>\n<ul><li>Obviously an important goal in a multiprocessor system is to balance the load between processors, so that one processor won\u2019t be sitting idle while another is overloaded.</li></ul>\n<blockquote>It runs both per-cluster and per-core. Per-cluster balancing pulls tasks between clusters and Per-core balancing spreads tasks within\u00a0cluster.</blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/634/1*HJrQvR13RCMDVTtot4S9tQ.png\"></figure><p>Thus, CFS balances runqueues not just based on weights\u00a0, but on a metric called <em>load</em>, which is the combination of the thread\u2019s weight and its average CPU utilization.</p>\n<ul><li>Note that moving processes from processor to processor to achieve load balancing works against the principle of processor affinity, and if not carefully managed, the savings gained by balancing the system can be lost in rebuilding caches. One option is to only allow migration when imbalance surpasses a given threshold.</li></ul>\n<p>Since load balancing is expensive the scheduler tries not to do it more often than is absolutely necessary. In addition to periodic load-balancing therefore, the scheduler can also trigger <em>emergency</em> load balancing when a core becomes\u00a0idle.</p>\n<h3>And this was\u00a0all!</h3>\n<p>Do share your feedback and suggestions in the comments section\u00a0below.</p>\n<h3>If you liked this blog, hit the \ud83d\udc4f\u00a0. Stay\u00a0tuned.</h3>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e9159cd2aa9b\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<blockquote><em>The symptoms of high CPU usage are familiar: the cursor moves jerkily and slowly, and applications begin to lag or shut down. The workstation might even begin to physically heat up as it strains to perform tasks. When diagnosing a malfunctioning system, these are signs you should start by checking the processor.</em></blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/483/1*OSfcIzl1U0ZgLkyHYMjEZw.png\"></figure><p>At the core of any computing device is the Central Processing Unit (CPU), or processor, which is responsible for fulfilling the user\u2019s instructions. A device\u2019s CPU only has the capacity to deal with so many processes or tasks at once, and when those resources are strained, the computer\u2019s performance begins to\u00a0suffer.</p>\n<p>Most processes are started at the same priority level and the Linux kernel schedules time for each task evenly on the processor. Have a CPU intensive process that can be run at a lower priority? Then you need to tell the scheduler about\u00a0it!</p>\n<p>There are at least three ways in which you can control how much CPU time a process\u00a0gets:</p>\n<p>Use the <strong>nice </strong>command to manually lower the task\u2019s priority.</p>\n<p>A thread\u2019s weight is essentially its priority, or niceness in UNIX parlance. Threads with lower niceness have higher weights and vice\u00a0versa.</p>\n<p>The nice command tweaks the priority level of a process so that it runs less frequently. <strong>This is useful when you need to run a CPU intensive task as a background or batch job</strong>. The niceness level ranges from -20 (most favorable scheduling) to 19 (least favorable). Processes on Linux are started with a niceness of 0 by default. The nice command (without any additional parameters) will start a process with a niceness of 10. At that level the scheduler will see it as a lower priority task and give it less CPU resources.</p>\n<p>Use the <strong>cpulimit</strong> command to repeatedly pause the process so that it doesn't exceed a certain\u00a0limit.</p>\n<p>cpulimit<strong> is useful when you want to ensure that a process doesn't use more than a certain portion of the CPU.</strong> The disadvantage over nice is that the process can't use all of the available CPU time when the system is idle. It does not change the nice value of the process, instead it monitors and controls the real-world CPU\u00a0usage.</p>\n<p>Use Linux\u2019s built-in <strong>control groups</strong>, a mechanism which tells the scheduler to limit the amount of resources available to the\u00a0process.</p>\n<p>Control groups (cgroups) are a Linux kernel feature that allows you to specify how the kernel should allocate specific resources to a group of processes. With cgroups you can specify how much CPU time, system memory, network bandwidth, or combinations of these resources can be used by the processes residing in a certain\u00a0group.</p>\n<p><strong>The advantage of control groups over </strong>nice<strong> or </strong>cpulimit<strong> is that the limits are applied to a set of processes, rather than to just one.</strong> Also, nice or cpulimit only limit the CPU usage of a process, whereas cgroups can limit other process resources.</p>\n<p>By judiciously using cgroups the resources of entire subsystems of a server can be controlled. For example in CoreOS, the minimal Linux distribution designed for massive server deployments, the upgrade processes are controlled by a cgroup. This means the downloading and installing of system updates doesn\u2019t affect system performance.</p>\n<p>Linux uses a<strong> <em>Completely Fair Scheduling</em> </strong>(CFS) algorithm, which is an implementation of <em>weighted fair queueing</em>\u00a0(WFQ).</p>\n<p>Scheduling goal is to maximize power efficiency with only a modest performance sacrifice. the scheduler decides when one process ceases<br>running and the other\u00a0begins.</p>\n<p>When an interrupt happens, scheduler has to decide whether to grant CPU to some other process and, if so, to which one. The amount of time a process gets to run is called timeslice of a\u00a0process</p>\n<h3>What process should the scheduler pick\u00a0next?</h3>\n<p>The scheduler should maximize CPU utilization.</p>\n<p>Imagine a single CPU system to start with: CFS time-slices the CPU among running threads. There is a fixed time interval during which each thread in the system must run at least once. This interval is divided into <em>timeslices</em> that are allocated to threads according to their\u00a0weights.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/495/1*G9FH4eVULC7sZeaK-3Cn8Q.png\"></figure><p>A running thread accumulates <strong><em>vruntime</em> </strong>(runtime / weight). When a thread\u2019s vruntime exceeds its assigned timeslice it will be pre-empted.</p>\n<blockquote>\n<em>Threads are organized in a runqueue, implemented as a</em><strong><em> red-black tree</em></strong><em>, in which the threads are sorted in the increasing order of their vruntime. When a CPU looks for a new thread to run it picks the leftmost node in the red-black tree, which contains the thread with the smallest vruntime.</em>\n</blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/593/1*JgkihpQPz3H63zT4OP2ehw.png\"></figure><p>So far so good, but now we have to talk about multi-core systems\u2026</p>\n<p>Firstly we need per-core runqueues so that context switches can be fast. Now we have a new problem of balancing work across multiple runqueues.</p>\n<blockquote>\n<em>Consider a dual-core system with two runqueues that are not balanced. Suppose that one queue has one low-priority thread and another has ten high-priority threads. If each core looked for work only in its local runqueue, then high-priority threads would get a lot less CPU time than the low-priority thread, which is not what we want. We could have each core checknot only its runqueue but also the queues of other cores,but this would defeat the purpose of per-core runqueues. Therefore, what Linux and most other schedulers do is periodically run a </em><strong><em>load-balancing algorithm</em></strong><em> that will keep the queues roughly balanced.</em>\n</blockquote>\n<h3>How Load balancing works?</h3>\n<ul><li>Obviously an important goal in a multiprocessor system is to balance the load between processors, so that one processor won\u2019t be sitting idle while another is overloaded.</li></ul>\n<blockquote>It runs both per-cluster and per-core. Per-cluster balancing pulls tasks between clusters and Per-core balancing spreads tasks within\u00a0cluster.</blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/634/1*HJrQvR13RCMDVTtot4S9tQ.png\"></figure><p>Thus, CFS balances runqueues not just based on weights\u00a0, but on a metric called <em>load</em>, which is the combination of the thread\u2019s weight and its average CPU utilization.</p>\n<ul><li>Note that moving processes from processor to processor to achieve load balancing works against the principle of processor affinity, and if not carefully managed, the savings gained by balancing the system can be lost in rebuilding caches. One option is to only allow migration when imbalance surpasses a given threshold.</li></ul>\n<p>Since load balancing is expensive the scheduler tries not to do it more often than is absolutely necessary. In addition to periodic load-balancing therefore, the scheduler can also trigger <em>emergency</em> load balancing when a core becomes\u00a0idle.</p>\n<h3>And this was\u00a0all!</h3>\n<p>Do share your feedback and suggestions in the comments section\u00a0below.</p>\n<h3>If you liked this blog, hit the \ud83d\udc4f\u00a0. Stay\u00a0tuned.</h3>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e9159cd2aa9b\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["technology","linux","performance-management","operating-systems","computer-science"]},{"title":"How to control which core a process runs on?","pubDate":"2020-07-15 07:53:58","link":"https://medium.com/@paruldhingra/how-to-control-which-core-a-process-runs-on-50ca029a3999?source=rss-6e9b39ccfd81------2","guid":"https://medium.com/p/50ca029a3999","author":"Parul Dhingra","thumbnail":"https://cdn-images-1.medium.com/max/699/1*N_-CHDGNIQYp-tZUuzPUNg.png","description":"\n<p>The Key goals for any power requirement efforts on a mobile device are to ensure <strong>overall battery usage is optimal</strong>. The objective of the tuning efforts is to maximize performance without impacting power utilization as much as possible.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/699/1*N_-CHDGNIQYp-tZUuzPUNg.png\"></figure><p>In a single core system, the OS allows multiple processes to run by sharing CPU time with the multiple processes. This is called concurrency, which gives the illusion of multiple processes executing at once, but is in fact just using a scheduler to give each process dedicated time on the CPU. The time associated with switching processes on a single core is overhead caused by context switching.</p>\n<p>When a multi-core processor is available to an OS (e.g., Linux), the scheduler will do its best to allow processes to run simultaneously (by placing processes on different cores) in addition to running concurrently (different processes on the same\u00a0core).</p>\n<blockquote>In case of single threaded heavy application, you will see that the main thread migrates between different CPUs frequently and it runs for some duration on each CPU. This frequent context switching for such big thread may cause power hit/performance hit, so we need to affine that particular thread to a fixed CPU or a range of CPUs so that it won\u2019t migrate and save the power/perf.</blockquote>\n<p>To control which core a process runs on, we can tell the scheduler to give a process a certain affinity towards a given set of\u00a0CPUs.</p>\n<p><strong>Ever heard of the term processor affinity?</strong></p>\n<p>It\u2019s a feature that allows you to bind or unbind processes to a particular central processing unit, or a range of\u00a0CPUs.</p>\n<p>Yes, you can tell the system which CPU core(s) should be used to run a particular process. It\u2019s the task of the JVM\u2019s optimizer to ensure, that objects affine to one thread are placed close to each other in memory to fit into one CPU\u2019s cache but place objects affine to different threads not too close to each other to avoid that they share a cache line as otherwise two CPUs/cores have to synchronize them too\u00a0often.</p>\n<p>The<strong> taskset </strong>command allows you to set or retrieve a process given its pid, or to launch a new command with a given CPU affinity.</p>\n<p>Following is its\u00a0syntax:</p>\n<p>taskset [options] mask command [argument\u2026]<br>taskset [options] -p [mask]\u00a0pid</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/360/1*Xkw_yXe9Z5kGjdGaQksKVg.png\"></figure><p>So hexadecimal value \u2018f\u2019 here means the process can run on any of the 4 processor cores:\u00a00,1,2,3.</p>\n<p>If you want the output to be in terms of CPU range, you can add the -c command line\u00a0option.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/325/1*LeCB2a7GndwTLdS2JFen9g.png\"></figure><p>And then you can again check the new affinity using the following command:<br>taskset -p\u00a05941</p>\n<p><strong>How to assign a range of CPUs while changing affinity?</strong></p>\n<p>This is no big deal. All you have to do is to add the -c command-line option to the command we\u2019ve used in the previous section along with the CPU core range as\u00a0input.</p>\n<p>Here is an\u00a0example:</p>\n<p>taskset -cp 0,3\u00a05941</p>\n<p>Following is the output produced in this case:<br>pid 5941\u2019s current affinity list: 0<br>pid 5941\u2019s new affinity list:\u00a00,3</p>\n<p>When taskset returns, it is guaranteed that the given program has been scheduled to a legal\u00a0CPU.</p>\n<h3>And this was\u00a0all!</h3>\n<p>Do share your feedback and suggestions in the comments section\u00a0below.</p>\n<h3>If you liked this blog, hit the \ud83d\udc4f\u00a0. Stay\u00a0tuned.</h3>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=50ca029a3999\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>The Key goals for any power requirement efforts on a mobile device are to ensure <strong>overall battery usage is optimal</strong>. The objective of the tuning efforts is to maximize performance without impacting power utilization as much as possible.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/699/1*N_-CHDGNIQYp-tZUuzPUNg.png\"></figure><p>In a single core system, the OS allows multiple processes to run by sharing CPU time with the multiple processes. This is called concurrency, which gives the illusion of multiple processes executing at once, but is in fact just using a scheduler to give each process dedicated time on the CPU. The time associated with switching processes on a single core is overhead caused by context switching.</p>\n<p>When a multi-core processor is available to an OS (e.g., Linux), the scheduler will do its best to allow processes to run simultaneously (by placing processes on different cores) in addition to running concurrently (different processes on the same\u00a0core).</p>\n<blockquote>In case of single threaded heavy application, you will see that the main thread migrates between different CPUs frequently and it runs for some duration on each CPU. This frequent context switching for such big thread may cause power hit/performance hit, so we need to affine that particular thread to a fixed CPU or a range of CPUs so that it won\u2019t migrate and save the power/perf.</blockquote>\n<p>To control which core a process runs on, we can tell the scheduler to give a process a certain affinity towards a given set of\u00a0CPUs.</p>\n<p><strong>Ever heard of the term processor affinity?</strong></p>\n<p>It\u2019s a feature that allows you to bind or unbind processes to a particular central processing unit, or a range of\u00a0CPUs.</p>\n<p>Yes, you can tell the system which CPU core(s) should be used to run a particular process. It\u2019s the task of the JVM\u2019s optimizer to ensure, that objects affine to one thread are placed close to each other in memory to fit into one CPU\u2019s cache but place objects affine to different threads not too close to each other to avoid that they share a cache line as otherwise two CPUs/cores have to synchronize them too\u00a0often.</p>\n<p>The<strong> taskset </strong>command allows you to set or retrieve a process given its pid, or to launch a new command with a given CPU affinity.</p>\n<p>Following is its\u00a0syntax:</p>\n<p>taskset [options] mask command [argument\u2026]<br>taskset [options] -p [mask]\u00a0pid</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/360/1*Xkw_yXe9Z5kGjdGaQksKVg.png\"></figure><p>So hexadecimal value \u2018f\u2019 here means the process can run on any of the 4 processor cores:\u00a00,1,2,3.</p>\n<p>If you want the output to be in terms of CPU range, you can add the -c command line\u00a0option.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/325/1*LeCB2a7GndwTLdS2JFen9g.png\"></figure><p>And then you can again check the new affinity using the following command:<br>taskset -p\u00a05941</p>\n<p><strong>How to assign a range of CPUs while changing affinity?</strong></p>\n<p>This is no big deal. All you have to do is to add the -c command-line option to the command we\u2019ve used in the previous section along with the CPU core range as\u00a0input.</p>\n<p>Here is an\u00a0example:</p>\n<p>taskset -cp 0,3\u00a05941</p>\n<p>Following is the output produced in this case:<br>pid 5941\u2019s current affinity list: 0<br>pid 5941\u2019s new affinity list:\u00a00,3</p>\n<p>When taskset returns, it is guaranteed that the given program has been scheduled to a legal\u00a0CPU.</p>\n<h3>And this was\u00a0all!</h3>\n<p>Do share your feedback and suggestions in the comments section\u00a0below.</p>\n<h3>If you liked this blog, hit the \ud83d\udc4f\u00a0. Stay\u00a0tuned.</h3>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=50ca029a3999\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["performance-management","power-management","operating-systems","linux","computer-science"]}]}